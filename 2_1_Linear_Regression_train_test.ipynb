{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2478ba5b",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41027a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import shap\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22973a6a",
   "metadata": {},
   "source": [
    "# Importation des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedcdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary_train = pd.read_csv(\"df_stationary_train.csv\", index_col=\"date\")\n",
    "df_stationary_test = pd.read_csv(\"df_stationary_test.csv\", index_col=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91223b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>TB3MS</th>\n",
       "      <th>RPI</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>BUSLOANS</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>OILPRICEx</th>\n",
       "      <th>M2SL</th>\n",
       "      <th>USREC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-01-01</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.091980</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>-0.006156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-02-01</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.076964</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>-0.025663</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-03-01</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>-0.070857</td>\n",
       "      <td>-0.008356</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-04-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>-0.025915</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>-0.040442</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>-0.018121</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>-0.010090</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            UNRATE  TB3MS       RPI    INDPRO  DPCERA3M086SBEA   S&P 500  \\\n",
       "date                                                                       \n",
       "1960-01-01    -0.8   0.30  0.020977  0.091980         0.001204  0.017909   \n",
       "1960-02-01    -1.1  -0.19  0.014565  0.076964         0.006009 -0.025663   \n",
       "1960-03-01    -0.2  -1.18  0.006250  0.007961         0.021240 -0.070857   \n",
       "1960-04-01     0.0  -1.12  0.006489 -0.025915         0.033752 -0.040442   \n",
       "1960-05-01     0.0  -0.67  0.007747 -0.018121         0.009040 -0.010090   \n",
       "\n",
       "            BUSLOANS  CPIAUCSL  OILPRICEx      M2SL  USREC  \n",
       "date                                                        \n",
       "1960-01-01  0.011578 -0.006156        0.0  0.001323      0  \n",
       "1960-02-01  0.011905 -0.003767        0.0  0.002007      0  \n",
       "1960-03-01 -0.008356 -0.005455        0.0  0.001324      0  \n",
       "1960-04-01 -0.009098  0.005090        0.0  0.000634      1  \n",
       "1960-05-01 -0.000359  0.003383        0.0  0.003977      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stationary_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aff52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary_train.index = pd.to_datetime(df_stationary_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58729f82",
   "metadata": {},
   "source": [
    "# stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84d84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ==========================================================\n",
    "# üîß Hypoth√®se : df_stationary_train contient la cible 'Y'\n",
    "# ==========================================================\n",
    "\n",
    "# --- D√©finir les features\n",
    "features = [c for c in df_stationary_train.columns if c != \"UNRATE\"]\n",
    "\n",
    "# === Param√®tres ===\n",
    "step_size = 12\n",
    "winsor_level = 0.01\n",
    "norm_var = True\n",
    "\n",
    "# === Conteneurs ===\n",
    "models = []\n",
    "coefs = []\n",
    "train_periods = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e9e024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(12, 360, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(step_size, len(df_stationary_train), step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b632dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 5)\n"
     ]
    }
   ],
   "source": [
    "a = range(1, 5 ,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea85d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for t, end in enumerate(a):\n",
    "    #print(t)\n",
    "    print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91dffcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNRATE             0\n",
       "TB3MS              0\n",
       "RPI                0\n",
       "INDPRO             0\n",
       "DPCERA3M086SBEA    0\n",
       "S&P 500            0\n",
       "BUSLOANS           0\n",
       "CPIAUCSL           0\n",
       "OILPRICEx          0\n",
       "M2SL               0\n",
       "USREC              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stationary_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c1c02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5e99c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Fit (Ridge)\u001b[39;00m\n\u001b[32m     84\u001b[39m model = Ridge(alpha=\u001b[32m1.0\u001b[39m, fit_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Pr√©vision √† T+h avec X_T (derni√®re obs de la fen√™tre)\u001b[39;00m\n\u001b[32m     88\u001b[39m origin_date = df_train_local.index[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1238\u001b[39m, in \u001b[36mRidge.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1236\u001b[39m _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X), \u001b[38;5;28mself\u001b[39m.solver)\n\u001b[32m   1237\u001b[39m xp, _ = get_namespace(X, y, sample_weight)\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_accept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().fit(X, y, sample_weight=sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "try:\n",
    "    from scipy.stats import pearsonr\n",
    "    _has_scipy = True\n",
    "except Exception:\n",
    "    _has_scipy = False\n",
    "\n",
    "# ====== Hyperparam√®tres ======\n",
    "h = 12                  # horizon de pr√©vision (de ta conf)\n",
    "step_size = 12          # refit annuel\n",
    "winsor_level = 0.01     # winsorisation 1% - 99%\n",
    "norm_var = True         # normalisation z-score\n",
    "target = \"UNRATE\"\n",
    "\n",
    "# ====== P√©riode TRAIN ======\n",
    "train_start, train_end = \"1960-01\", \"1989-12\"\n",
    "df = df_stationary_train.loc[train_start:train_end].copy()\n",
    "\n",
    "# ====== Features : on utilise exactement celles que tu as d√©j√† ======\n",
    "cols_tx = list(features)\n",
    "\n",
    "# S'assurer qu'on a des lignes compl√®tes\n",
    "df = df.dropna(subset=[target] + cols_tx).copy()\n",
    "\n",
    "# ====== Containers ======\n",
    "models, coefs, train_periods = [], [], []\n",
    "yhat_list, ytrue_list, forecast_dates = [], [], []\n",
    "\n",
    "# ====== Aides ======\n",
    "def r2_origin_reg(y, yhat):\n",
    "    if len(y) == 0: return np.nan\n",
    "    denom = float(np.dot(yhat, yhat))\n",
    "    if denom == 0: return np.nan\n",
    "    b = float(np.dot(yhat, y)) / denom\n",
    "    sse = float(np.sum((y - b * yhat) ** 2))\n",
    "    sst = float(np.sum((y - y.mean()) ** 2))\n",
    "    return 1 - (sse / sst) if sst > 0 else np.nan\n",
    "\n",
    "def corr_pvalue(y, yhat):\n",
    "    if len(y) < 3: return np.nan, np.nan\n",
    "    if _has_scipy:\n",
    "        r, p = pearsonr(y, yhat); return float(r), float(p)\n",
    "    r = float(np.corrcoef(y, yhat)[0, 1])\n",
    "    n = len(y)\n",
    "    t_stat = r * np.sqrt((n - 2) / max(1e-12, 1 - r**2))\n",
    "    from math import erf\n",
    "    Phi = lambda x: 0.5 * (1 + erf(x / np.sqrt(2)))\n",
    "    p = 2 * (1 - Phi(abs(t_stat)))\n",
    "    return r, float(max(min(p, 1.0), 0.0))\n",
    "\n",
    "# ====== Boucle rolling-origin (expanding) sur TRAIN ======\n",
    "# Il faut au moins h+1 obs pour aligner (X_t, y_{t+h})\n",
    "min_needed = h + 1\n",
    "start_end = max(step_size, min_needed)\n",
    "\n",
    "idx_all = df.index\n",
    "for t, end in enumerate(range(start_end, len(df), step_size)):\n",
    "    df_train_local = df.iloc[:end].copy()\n",
    "    n = len(df_train_local)\n",
    "\n",
    "    # Aligner (X_t, y_{t+h}) sans shift/dropna implicite\n",
    "    X_train_raw = df_train_local[cols_tx].iloc[:n - h].copy()\n",
    "    y_train = df_train_local[target].iloc[h:].copy()\n",
    "    X_train_raw.index = y_train.index  # aligner les index temporels\n",
    "\n",
    "    # Winsorisation (sur toutes les features ‚Äî tes lags sont d√©j√† dans les features)\n",
    "    lower = X_train_raw.quantile(winsor_level)\n",
    "    upper = X_train_raw.quantile(1 - winsor_level)\n",
    "    X_train_w = X_train_raw.clip(lower=lower, upper=upper, axis=1)\n",
    "\n",
    "    # Normalisation (z-score) avec stats de la fen√™tre courante\n",
    "    if norm_var:\n",
    "        mean_ = X_train_w.mean()\n",
    "        std_ = X_train_w.std().replace(0, 1)\n",
    "        X_train = (X_train_w - mean_) / std_\n",
    "    else:\n",
    "        X_train = X_train_w\n",
    "\n",
    "    # Fit (Ridge)\n",
    "    model = Ridge(alpha=1.0, fit_intercept=True, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Pr√©vision √† T+h avec X_T (derni√®re obs de la fen√™tre)\n",
    "    origin_date = df_train_local.index[-1]\n",
    "    x_o = df_train_local.loc[origin_date, cols_tx].copy()\n",
    "    x_o = x_o.clip(lower=lower, upper=upper)\n",
    "    if norm_var:\n",
    "        x_o = (x_o - mean_).divide(std_)\n",
    "\n",
    "    yhat = float(model.predict(x_o.values.reshape(1, -1)))\n",
    "\n",
    "    # Date cible T+h (√©valuer seulement si encore dans TRAIN)\n",
    "    end_pos = idx_all.get_loc(origin_date)\n",
    "    target_pos = end_pos + h\n",
    "    if target_pos < len(idx_all):\n",
    "        y_true_date = idx_all[target_pos]\n",
    "        if y_true_date <= pd.to_datetime(train_end):\n",
    "            y_true = float(df.loc[y_true_date, target])\n",
    "            yhat_list.append(yhat)\n",
    "            ytrue_list.append(y_true)\n",
    "            forecast_dates.append(y_true_date)\n",
    "\n",
    "    # Sauvegardes\n",
    "    models.append(model)\n",
    "    coefs.append(pd.Series(model.coef_, index=cols_tx))\n",
    "    train_periods.append(origin_date)\n",
    "\n",
    "    print(f\"[{t:02d}] Fin {origin_date.strftime('%Y-%m')} ‚Äî mod√®le entra√Æn√© ({len(X_train)} obs). \"\n",
    "          f\"Pr√©vision pour {(y_true_date.strftime('%Y-%m') if target_pos < len(idx_all) else 'N/A')}: {yhat:.4f}\")\n",
    "\n",
    "# ====== √âvaluation ROLLING sur TRAIN ======\n",
    "y_true_arr = np.array(ytrue_list, dtype=float)\n",
    "y_pred_arr = np.array(yhat_list, dtype=float)\n",
    "\n",
    "if len(y_true_arr) == 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Aucune date cible (T+{h}) ne tombe dans le TRAIN {train_start}‚Äì{train_end}.\")\n",
    "else:\n",
    "    r2 = r2_score(y_true_arr, y_pred_arr)\n",
    "    r2_null = r2_origin_reg(y_true_arr, y_pred_arr)\n",
    "    mae = mean_absolute_error(y_true_arr, y_pred_arr)             # m√©trique principale (MAE)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_arr, y_pred_arr))    # compatible toutes versions de sklearn\n",
    "    corr, pval = corr_pvalue(y_true_arr, y_pred_arr)\n",
    "    amd = float(abs(np.mean(y_true_arr - y_pred_arr)))\n",
    "\n",
    "    print(\"\\n=== √âvaluation TRAIN (rolling forecasts) ‚Äî h={} ===\".format(h))\n",
    "    print(f\"P√©riode TRAIN    : {train_start} ‚Üí {train_end}\")\n",
    "    print(f\"Points √©valu√©s   : {len(y_true_arr)} \"\n",
    "          f\"(de {pd.to_datetime(forecast_dates[0]).strftime('%Y-%m')} \"\n",
    "          f\"√† {pd.to_datetime(forecast_dates[-1]).strftime('%Y-%m')})\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(f\"MAE              : {mae:.4f}\")\n",
    "    print(f\"RMSE             : {rmse:.4f}\")\n",
    "    print(f\"R¬≤               : {r2:.4f}\")\n",
    "    print(f\"R¬≤ (OLS b=0)     : {r2_null:.4f}\")\n",
    "    print(f\"Corr√©lation      : {corr:.4f} (p={pval:.2e})\")\n",
    "    print(f\"Abs Mean Dev.    : {amd:.4f}\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"‚úÖ Backtest TRAIN termin√© (pr√©visions √† chaque fin de fen√™tre).\")\n",
    "\n",
    "# ====== Sauvegarde ======\n",
    "exp_results = {\n",
    "    \"models\": models,\n",
    "    \"coefs\": coefs,\n",
    "    \"train_periods\": train_periods,\n",
    "    \"features\": cols_tx,\n",
    "    \"forecast_dates\": forecast_dates,\n",
    "    \"y_true\": y_true_arr,\n",
    "    \"y_pred\": y_pred_arr,\n",
    "    \"params\": {\n",
    "        \"h\": h,\n",
    "        \"step_size\": step_size,\n",
    "        \"winsor_level\": winsor_level,\n",
    "        \"norm_var\": norm_var,\n",
    "        \"train_range\": (train_start, train_end),\n",
    "        \"method\": \"Ridge\",\n",
    "        \"lags_prebuilt\": True  # ‚úÖ on indique bien qu'ils √©taient d√©j√† dans les donn√©es\n",
    "    },\n",
    "    \"metrics_train\": {\n",
    "        \"mae\": float(mae) if len(y_true_arr) else None,\n",
    "        \"rmse\": float(rmse) if len(y_true_arr) else None,\n",
    "        \"r2\": float(r2) if len(y_true_arr) else None,\n",
    "        \"r2_origin\": float(r2_null) if len(y_true_arr) else None,\n",
    "        \"corr\": float(corr) if len(y_true_arr) else None,\n",
    "        \"pval\": float(pval) if len(y_true_arr) else None,\n",
    "        \"amd\": float(amd) if len(y_true_arr) else None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c547f0",
   "metadata": {},
   "source": [
    "# Evaluation globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9708fd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oos_train_h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score, mean_absolute_error, mean_squared_error\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m y_true = \u001b[43moos_train_h\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mUNRATE_true_h\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m      7\u001b[39m y_pred = oos_train_h[\u001b[33m\"\u001b[39m\u001b[33mUNRATE_pred_h\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m      9\u001b[39m r2 = r2_score(y_true, y_pred)\n",
      "\u001b[31mNameError\u001b[39m: name 'oos_train_h' is not defined"
     ]
    }
   ],
   "source": [
    "# === √âvaluation globale (TRAIN, horizon h=24) ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "y_true = oos_train_h[\"UNRATE_true_h\"].values\n",
    "y_pred = oos_train_h[\"UNRATE_pred_h\"].values\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "r2_null = r2_score(y_true, np.zeros_like(y_true))  # baseline b=0\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "corr, pval = pearsonr(y_true, y_pred)\n",
    "amd = np.mean(np.abs(y_true - np.mean(y_true)))\n",
    "\n",
    "print(\"\\n=== √âvaluation TRAIN (h=24) ===\")\n",
    "print(f\"R¬≤              : {r2:.4f}\")\n",
    "print(f\"R¬≤ (OLS b=0)    : {r2_null:.4f}\")\n",
    "print(f\"MAE             : {mae:.4f}\")\n",
    "print(f\"RMSE            : {rmse:.4f}\")\n",
    "print(f\"Corr√©lation     : {corr:.4f} (p={pval:.2e})\")\n",
    "print(f\"Abs Mean Dev.   : {amd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db18b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Mod√®le sauvegard√© avec succ√®s : models\\model_final.pkl\n",
      "\n",
      "=== Performance globale (TRAIN) ===\n",
      "R¬≤ (ensemble) : -0.1009\n",
      "R¬≤ (OLS b=0)  : -0.0000\n",
      "MAE            : 0.8792\n",
      "RMSE           : 1.1751\n",
      "Corr√©lation    : 0.5711 (p = 1.51e-32)\n",
      "Abs Mean Dev.  : 0.8289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import shap\n",
    "\n",
    "# ==========================================================\n",
    "# üìà √âVALUATION SUR LE TRAIN GLOBAL\n",
    "# ==========================================================\n",
    "features = exp_results[\"features\"]\n",
    "model_final = exp_results[\"models\"][-1]  # dernier mod√®le\n",
    "winsor_level = exp_results[\"params\"][\"winsor_level\"]\n",
    "norm_var = exp_results[\"params\"][\"norm_var\"]\n",
    "\n",
    "X_full = df_stationary_train[features].copy()\n",
    "Y_full = df_stationary_train[\"UNRATE\"].copy()\n",
    "\n",
    "# Winsorisation + normalisation globales\n",
    "lower_wins = X_full.quantile(winsor_level)\n",
    "upper_wins = X_full.quantile(1 - winsor_level)\n",
    "X_full = X_full.clip(lower=lower_wins, upper=upper_wins, axis=1)\n",
    "\n",
    "if norm_var:\n",
    "    mean_full = X_full.mean()\n",
    "    std_full = X_full.std().replace(0, 1)\n",
    "    X_full = (X_full - mean_full) / std_full\n",
    "\n",
    "# === Pr√©dictions et m√©triques\n",
    "y_pred = model_final.predict(X_full)\n",
    "\n",
    "r2 = r2_score(Y_full, y_pred)\n",
    "r2_null = r2_score(Y_full, np.zeros_like(Y_full))\n",
    "mae = mean_absolute_error(Y_full, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(Y_full, y_pred))\n",
    "corr, pval = pearsonr(Y_full, y_pred)\n",
    "amd = np.mean(np.abs(Y_full - np.mean(Y_full)))\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Chemin de sauvegarde\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Fichier du mod√®le\n",
    "model_path = os.path.join(model_dir, \"model_final.pkl\")\n",
    "\n",
    "# Dictionnaire complet √† sauvegarder\n",
    "saved_model = {\n",
    "    \"model\": model_final,\n",
    "    \"features\": features,\n",
    "    \"winsor_level\": winsor_level,\n",
    "    \"norm_var\": norm_var,\n",
    "    \"mean_full\": mean_full if norm_var else None,\n",
    "    \"std_full\": std_full if norm_var else None,\n",
    "}\n",
    "\n",
    "# Sauvegarde avec joblib\n",
    "joblib.dump(saved_model, model_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Mod√®le sauvegard√© avec succ√®s : {model_path}\")\n",
    "\n",
    "print(\"\\n=== Performance globale (TRAIN) ===\")\n",
    "print(f\"R¬≤ (ensemble) : {r2:.4f}\")\n",
    "print(f\"R¬≤ (OLS b=0)  : {r2_null:.4f}\")\n",
    "print(f\"MAE            : {mae:.4f}\")\n",
    "print(f\"RMSE           : {rmse:.4f}\")\n",
    "print(f\"Corr√©lation    : {corr:.4f} (p = {pval:.2e})\")\n",
    "print(f\"Abs Mean Dev.  : {amd:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad858c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Importance par permutation ===\n",
      "       variable  perm_mae_ratio  perm_rmse_ratio  perm_deviance\n",
      "          USREC        1.291937         1.257301       0.188454\n",
      "        S&P 500        1.127039         1.087991       0.082007\n",
      "            RPI        1.095025         1.073389       0.061341\n",
      "         INDPRO        1.013560         1.009293       0.008754\n",
      "       BUSLOANS        1.011036         1.002059       0.007124\n",
      "DPCERA3M086SBEA        1.010665         1.006124       0.007029\n",
      "      OILPRICEx        1.010090         0.998821       0.006860\n",
      "       CPIAUCSL        1.006380         1.002696       0.004358\n",
      "          TB3MS        1.003201         1.002882       0.002403\n",
      "           M2SL        0.998155         1.000433       0.001575\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üîç IMPORTANCE PAR PERMUTATION\n",
    "# ==========================================================\n",
    "def permutation_importance(model, X, y, metric=mean_absolute_error, n_repeats=30):\n",
    "    base_score = metric(y, model.predict(X))\n",
    "    results = []\n",
    "    for col in X.columns:\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_shuffled = X.copy()\n",
    "            X_shuffled[col] = np.random.permutation(X_shuffled[col])\n",
    "            score = metric(y, model.predict(X_shuffled))\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        results.append({\n",
    "            \"variable\": col,\n",
    "            \"perm_mae_ratio\": np.mean(scores) / base_score,\n",
    "            \"perm_rmse_ratio\": np.sqrt(mean_squared_error(y, model.predict(X_shuffled))) / rmse,\n",
    "            \"perm_deviance\": np.mean(np.abs(scores - base_score))\n",
    "        })\n",
    "    return pd.DataFrame(results).sort_values(\"perm_mae_ratio\", ascending=False)\n",
    "\n",
    "perm_df = permutation_importance(model_final, X_full, Y_full)\n",
    "\n",
    "print(\"\\n=== Importance par permutation ===\")\n",
    "print(perm_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf89f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Importance Shapley (shares) ===\n",
      "       variable  shap_mean_abs  shap_share\n",
      "          USREC       0.340596    0.312587\n",
      "        S&P 500       0.249643    0.229113\n",
      "            RPI       0.185142    0.169917\n",
      "         INDPRO       0.067299    0.061764\n",
      "       BUSLOANS       0.052476    0.048161\n",
      "DPCERA3M086SBEA       0.052252    0.047955\n",
      "      OILPRICEx       0.046934    0.043074\n",
      "       CPIAUCSL       0.043060    0.039519\n",
      "           M2SL       0.027262    0.025020\n",
      "          TB3MS       0.024941    0.022890\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================================\n",
    "# üí° IMPORTANCE SHAPLEY\n",
    "# ==========================================================\n",
    "explainer = shap.Explainer(model_final, X_full)\n",
    "shap_values = explainer(X_full)\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    \"variable\": X_full.columns,\n",
    "    \"shap_mean_abs\": np.abs(shap_values.values).mean(axis=0),\n",
    "})\n",
    "shap_df[\"shap_share\"] = shap_df[\"shap_mean_abs\"] / shap_df[\"shap_mean_abs\"].sum()\n",
    "shap_df = shap_df.sort_values(\"shap_mean_abs\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Importance Shapley (shares) ===\")\n",
    "print(shap_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84c6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== R√©sum√© comparatif (Permutation + SHAP) ===\n",
      "       variable  perm_mae_ratio  perm_rmse_ratio  perm_deviance  shap_mean_abs  shap_share\n",
      "       BUSLOANS        1.011036         1.002059       0.007124       0.052476    0.048161\n",
      "       CPIAUCSL        1.006380         1.002696       0.004358       0.043060    0.039519\n",
      "DPCERA3M086SBEA        1.010665         1.006124       0.007029       0.052252    0.047955\n",
      "         INDPRO        1.013560         1.009293       0.008754       0.067299    0.061764\n",
      "           M2SL        0.998155         1.000433       0.001575       0.027262    0.025020\n",
      "      OILPRICEx        1.010090         0.998821       0.006860       0.046934    0.043074\n",
      "            RPI        1.095025         1.073389       0.061341       0.185142    0.169917\n",
      "        S&P 500        1.127039         1.087991       0.082007       0.249643    0.229113\n",
      "          TB3MS        1.003201         1.002882       0.002403       0.024941    0.022890\n",
      "          USREC        1.291937         1.257301       0.188454       0.340596    0.312587\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üß© COMPARATIF GLOBAL\n",
    "# ==========================================================\n",
    "merged_df = pd.merge(perm_df, shap_df, on=\"variable\", how=\"outer\")\n",
    "print(\"\\n=== R√©sum√© comparatif (Permutation + SHAP) ===\")\n",
    "print(merged_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7b28b",
   "metadata": {},
   "source": [
    "# üìä M√©triques utilis√©es\n",
    "\n",
    "## 1) Performance globale\n",
    "\n",
    "**Coefficient de d√©termination (R¬≤)**  \n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}\n",
    "$$  \n",
    "‚û°Ô∏è Part de la variance expliqu√©e par le mod√®le (0 = pas mieux que la moyenne, 1 = parfait).\n",
    "\n",
    "**Erreur absolue moyenne (MAE)**  \n",
    "$$\n",
    "MAE = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "$$  \n",
    "‚û°Ô∏è √âcart absolu moyen entre valeurs r√©elles et pr√©dites, robuste aux outliers.\n",
    "\n",
    "**Erreur quadratique moyenne (RMSE)**  \n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$  \n",
    "‚û°Ô∏è Similaire au MAE mais p√©nalise davantage les grosses erreurs.\n",
    "\n",
    "**Corr√©lation de Pearson**  \n",
    "$$\n",
    "\\rho(y, \\hat{y}) = \\frac{\\text{Cov}(y, \\hat{y})}{\\sigma_y \\cdot \\sigma_{\\hat{y}}}\n",
    "$$  \n",
    "‚û°Ô∏è Mesure le degr√© de lien lin√©aire entre les pr√©dictions et les observations.\n",
    "\n",
    "**Abs Mean Deviance (AMD)**  \n",
    "$$\n",
    "AMD = \\frac{1}{n}\\sum_{i=1}^n |\\hat{y}_i - \\bar{\\hat{y}}|\n",
    "$$  \n",
    "‚û°Ô∏è √âcart moyen des pr√©dictions par rapport √† leur moyenne ; sert de r√©f√©rence pour la permutation pr√©diction-bas√©e.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Importance par permutation\n",
    "La relation entre Y et X d√©pend du temps. Quand on perturbe la s√©rie X (en la m√©langeant), on casse ce lien, et si l‚Äôerreur augmente, cela montre que X est une variable cl√© pour expliquer Y.\n",
    "\n",
    "**Ratio MAE**  \n",
    "$$\n",
    "PI^{MAE}_j = \\frac{MAE^{(perm)}_j}{MAE^{(base)}}\n",
    "$$  \n",
    "‚û°Ô∏è Si > 1, la variable est utile pour r√©duire l‚Äôerreur absolue.\n",
    "\n",
    "**Ratio RMSE**  \n",
    "$$\n",
    "PI^{RMSE}_j = \\frac{RMSE^{(perm)}_j}{RMSE^{(base)}}\n",
    "$$  \n",
    "‚û°Ô∏è Si > 1, la variable aide √† limiter les grosses erreurs.\n",
    "\n",
    "**D√©viance de pr√©diction**  \n",
    "$$\n",
    "PI^{dev}_j = \\frac{1}{n}\\sum_{i=1}^n \\big|\\hat{y}_i - \\hat{y}^{(perm)}_{i,j}\\big|\n",
    "$$  \n",
    "‚û°Ô∏è Mesure combien les pr√©dictions changent quand on brouille une variable.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Importance Shapley\n",
    "\n",
    "**D√©composition des pr√©dictions**  \n",
    "$$\n",
    "\\hat{y}_i = \\phi_0 + \\sum_{j=1}^p \\phi_{ij}\n",
    "$$  \n",
    "‚û°Ô∏è Chaque pr√©diction est expliqu√©e par une contribution \\(\\phi_{ij}\\) par variable.\n",
    "\n",
    "**Importance absolue moyenne**  \n",
    "$$\n",
    "\\text{Mean}(|\\phi_j|) = \\frac{1}{n}\\sum_{i=1}^n |\\phi_{ij}|\n",
    "$$  \n",
    "‚û°Ô∏è Contribution moyenne (absolue) d‚Äôune variable sur toutes les pr√©dictions.\n",
    "\n",
    "**Shapley share**  \n",
    "$$\n",
    "\\Gamma_j = \\frac{\\text{Mean}(|\\phi_j|)}{\\sum_{k=1}^p \\text{Mean}(|\\phi_k|)}\n",
    "$$  \n",
    "‚û°Ô∏è Part relative de la variable dans l‚Äôexplication totale (somme des parts = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6535a",
   "metadata": {},
   "source": [
    "## Interpr√©tation des r√©sultats \n",
    "\n",
    "### Performance globale \n",
    "- R¬≤ = 0.2266 ‚Üí mod√®le OLS explique ~23 % de la variance du ch√¥mage US.\n",
    "- MAE = 0.6774 ‚Üí en moyenne, l‚Äôerreur absolue est de 0.68 points (dans l‚Äôunit√© de la variable cible).\n",
    "- RMSE = 0.8750 ‚Üí un peu plus √©lev√© que le MAE, ce qui indique la pr√©sence de grosses erreurs ponctuelles.\n",
    "- Corr√©lation = 0.4760 (p ‚âà 10‚Åª¬≥‚Åµ) ‚Üí lien positif et significatif entre pr√©dictions et observations, mais seulement mod√©r√©. Ce qui peut expliquer la pr√©sence d'une relation \n",
    "- Abs Mean Deviance = 0.3370 ‚Üí sert ici de r√©f√©rence pour l‚Äôimportance pr√©diction-bas√©e : les pr√©dictions s‚Äô√©cartent en moyenne de 0.34 de leur propre moyenne.\n",
    "\n",
    "Lecture : le mod√®le OLS capte une partie utile du signal, mais laisse beaucoup de variance inexpliqu√©e. La corr√©lation faible illustre √©ventuellement la pr√©sence des relations non-lin√©aire, et non capt√©es par OLS.\n",
    "\n",
    "### üîπ 2. Importance par permutation\n",
    "- INDPRO (Industrial Production) : la plus influente. Sa permutation augmente MAE de +19 % et RMSE de +20 %, avec une forte d√©viance de pr√©diction (0.41).\n",
    "- TB3MS (Taux d‚Äôint√©r√™t √† 3 mois) : impact non n√©gligeable, ratios ~1.02 et d√©viance ~0.10.\n",
    "- BUSLOANS (Pr√™ts commerciaux) : r√¥le similaire (MAE ratio 1.017, d√©viance ~0.09).\n",
    "- S&P 500 : contribution mod√©r√©e, ratios l√©g√®rement > 1.\n",
    "- RPI, M2SL : influence plus faible mais perceptible.\n",
    "- CPIAUCSL, OILPRICEx, DPCERA3M086SBEA : quasi neutres (ratios ‚âà 1, d√©viance tr√®s faible).\n",
    "\n",
    "Lecture : INDPRO domine largement la performance, les autres apportent des compl√©ments mais plus modestes.\n",
    "\n",
    "### üîπ 3. Importance Shapley (shares)\n",
    "- INDPRO : ~52 % de l‚Äôexplication totale des pr√©dictions ‚Üí coh√©rence parfaite avec la permutation.\n",
    "- TB3MS (12 %) + BUSLOANS (12 %) : deux autres piliers importants.\n",
    "- S&P 500 (9,7 %) : contribue de fa√ßon notable.\n",
    "- M2SL (5 %), RPI (3 %), CPIAUCSL (3,5 %) : apports plus secondaires.\n",
    "- OILPRICEx et DPCERA3M086SBEA (<2 %) : quasi n√©gligeables dans ce mod√®le.\n",
    "\n",
    "Lecture : INDPRO est la variable macro√©conomique centrale, suivie par des indicateurs financiers (taux courts, pr√™ts bancaires, march√© actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3b489",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "saved_model = joblib.load(\"models/model_final.pkl\")\n",
    "model_final = saved_model[\"model\"]\n",
    "features = saved_model[\"features\"]\n",
    "winsor_level = saved_model[\"winsor_level\"]\n",
    "norm_var = saved_model[\"norm_var\"]\n",
    "mean_full = saved_model[\"mean_full\"]\n",
    "std_full = saved_model[\"std_full\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Travaux pratiques Bases)",
   "language": "python",
   "name": "venv-travaux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
