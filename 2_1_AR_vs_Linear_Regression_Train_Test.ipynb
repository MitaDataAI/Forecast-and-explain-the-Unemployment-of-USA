{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1ac7487",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2606ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, pickle, joblib\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e379e4f",
   "metadata": {},
   "source": [
    "# Importation des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7ca957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary = pd.read_csv(\"df_stationary.csv\", index_col=\"date\")\n",
    "df_stationary_unrate = df_stationary[\"UNRATE\"]\n",
    "y = df_stationary_unrate.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c496ff",
   "metadata": {},
   "source": [
    "# Pr√©paration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09685c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ S√©rie pr√™te : 1960-01-01 ‚Üí 2025-08-01 | n=788 | freq=MS\n"
     ]
    }
   ],
   "source": [
    "# V√©rifie que l‚Äôindex est bien une date (sinon essaie de le convertir)\n",
    "if not isinstance(y.index, (pd.DatetimeIndex, pd.PeriodIndex)):\n",
    "    y.index = pd.to_datetime(y.index, errors=\"coerce\")\n",
    "\n",
    "# am√©nager la fr√©quence mensuelle (d√©but de mois)\n",
    "y.index = y.index.to_period(\"M\").to_timestamp(how=\"start\")\n",
    "y = y.sort_index().asfreq(\"MS\").astype(float).dropna()\n",
    "\n",
    "print(f\"‚úÖ S√©rie pr√™te : {y.index.min().date()} ‚Üí {y.index.max().date()} | n={len(y)} | freq={y.index.freqstr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60b1d0",
   "metadata": {},
   "source": [
    "# 1- Mod√®le AutoRegression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "943a600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# AR(1) ‚Äî Pseudo-OOS continu (h=12), p=1 fixe + BAGGING (bootstrap en blocs)\n",
    "# ==========================================\n",
    "# ---------- Param√®tres ----------\n",
    "h = 12\n",
    "min_train_n = 36\n",
    "trend = \"c\"\n",
    "p_fixed = 1\n",
    "\n",
    "# ---------- Nouveaux param√®tres bagging ----------\n",
    "use_bagging = True      # ‚Üê interrupteur ON/OFF\n",
    "B_boot = 30            # nb de r√©-√©chantillonnages\n",
    "L_block = 12            # taille de bloc (mois) pour moving-block bootstrap\n",
    "rng = np.random.default_rng(123)  # seed bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea27c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Utilitaires bootstrap ----------\n",
    "def moving_block_bootstrap(arr, L, rng):\n",
    "    \"\"\"Concat√®ne des blocs contigus de taille L tir√©s al√©atoirement jusqu'√† longueur n.\"\"\"\n",
    "    n = len(arr)\n",
    "    if L <= 0 or L > n:\n",
    "        raise ValueError(\"L_block invalide\")\n",
    "    nb = int(np.ceil(n / L))\n",
    "    starts = rng.integers(0, n - L + 1, size=nb)\n",
    "    out = np.concatenate([arr[s:s+L] for s in starts])[:n]\n",
    "    return out\n",
    "\n",
    "def bagged_h_forecast_AR1(y_tr, h, trend, B, L, rng):\n",
    "    \"\"\"\n",
    "    Pr√©vision √† horizon h par bagging (residual moving-block bootstrap) pour AR(1).\n",
    "    Retourne (yhat_mean, yhat_dist, base_pred)\n",
    "    \"\"\"\n",
    "    base_model = AutoReg(y_tr, lags=1, old_names=False, trend=trend).fit()\n",
    "    base_fc = base_model.predict(start=len(y_tr), end=len(y_tr) + h - 1)\n",
    "    base_pred = float(base_fc.iloc[-1])\n",
    "\n",
    "    resid = base_model.resid.values\n",
    "    fitted = (y_tr.iloc[-len(resid):].values - resid)  # yÃÇ_t align√© aux r√©sidus\n",
    "\n",
    "    boot_preds = []\n",
    "    for _ in range(B):\n",
    "        res_b = moving_block_bootstrap(resid, L, rng)   # bootstrap des r√©sidus\n",
    "        y_b = fitted + res_b                             # s√©rie bootstrap√©e\n",
    "        m_b = AutoReg(pd.Series(y_b, index=y_tr.index[-len(y_b):]),\n",
    "                      lags=1, old_names=False, trend=trend).fit()\n",
    "        fc_b = m_b.predict(start=len(y_tr), end=len(y_tr) + h - 1)\n",
    "        boot_preds.append(float(fc_b.iloc[-1]))\n",
    "    return float(np.mean(boot_preds)), np.array(boot_preds), base_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c95c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 1960-01-01 ‚Üí 2025-08-01  (n=788) | freq=MS\n"
     ]
    }
   ],
   "source": [
    "# ---------- S√©curisation de la s√©rie y ----------\n",
    "y = pd.Series(y.astype(float).values, index=pd.to_datetime(y.index)).asfreq(\"MS\").dropna()\n",
    "print(f\"y: {y.index.min().date()} ‚Üí {y.index.max().date()}  (n={len(y)}) | freq={y.index.freqstr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f87b04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Boucle pseudo-OOS continue ----------\n",
    "rows = []\n",
    "last_model = None\n",
    "last_fit_end = None\n",
    "\n",
    "last_t_end = y.index.max() - relativedelta(months=h)\n",
    "\n",
    "for t_end in y.index:\n",
    "    if t_end > last_t_end:\n",
    "        break\n",
    "\n",
    "    y_tr = y.loc[:t_end]\n",
    "    if len(y_tr) < max(min_train_n, p_fixed + 1):\n",
    "        continue\n",
    "\n",
    "    # fit AR(1) base (utile pour sauvegarde / comparaison)\n",
    "    ar1 = AutoReg(y_tr, lags=p_fixed, old_names=False, trend=trend).fit()\n",
    "    last_model = ar1\n",
    "    last_fit_end = t_end\n",
    "\n",
    "    # ----- Pr√©vision √† h mois (bagging ou base) -----\n",
    "    if use_bagging:\n",
    "        yhat_h, yhat_dist, yhat_h_base = bagged_h_forecast_AR1(\n",
    "            y_tr=y_tr, h=h, trend=trend, B=B_boot, L=L_block, rng=rng\n",
    "        )\n",
    "        yhat_p05 = float(np.percentile(yhat_dist, 5))\n",
    "        yhat_p95 = float(np.percentile(yhat_dist, 95))\n",
    "    else:\n",
    "        fc = ar1.predict(start=len(y_tr), end=len(y_tr) + h - 1)\n",
    "        yhat_h = float(fc.iloc[-1])\n",
    "        yhat_h_base = yhat_h\n",
    "        yhat_p05 = np.nan\n",
    "        yhat_p95 = np.nan\n",
    "\n",
    "    t_fore = t_end + relativedelta(months=h)\n",
    "    if t_fore in y.index:\n",
    "        rows.append((t_fore, yhat_h, float(y.loc[t_fore]), yhat_p05, yhat_p95, yhat_h_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b55e0000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = 741\n",
      "               y_hat  y_true  y_hat_p05  y_hat_p95  y_hat_base\n",
      "date                                                          \n",
      "1963-12-01  0.070473     0.0  -0.149798   0.286016   -0.080890\n",
      "1964-01-01  0.017682    -0.1  -0.194683   0.225812    0.141077\n",
      "1964-02-01  0.090722    -0.5  -0.050079   0.265508    0.408114\n"
     ]
    }
   ],
   "source": [
    "# ---------- DataFrame OOS ----------\n",
    "if rows:\n",
    "    df_oos_ar1 = (\n",
    "        pd.DataFrame(rows, columns=[\"date\", \"y_hat\", \"y_true\", \"y_hat_p05\", \"y_hat_p95\", \"y_hat_base\"])\n",
    "          .set_index(\"date\").sort_index()\n",
    "    )\n",
    "else:\n",
    "    df_oos_ar1 = pd.DataFrame(columns=[\"y_hat\", \"y_true\", \"y_hat_p05\", \"y_hat_p95\", \"y_hat_base\"])\n",
    "    df_oos_ar1.index = pd.to_datetime(pd.Index([]))\n",
    "\n",
    "print(f\"\\n‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = {len(df_oos_ar1)}\")\n",
    "print(df_oos_ar1.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a7c678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Validation 83‚Äì89 ‚Äî n=84 | MAE=0.817 | RMSE=1.234 | R¬≤=-0.949\n",
      "üìä Test 90‚Äì2025 ‚Äî n=428 | MAE=0.867 | RMSE=1.600 | R¬≤=-0.100\n"
     ]
    }
   ],
   "source": [
    "# ---------- (facultatif) Scores par p√©riode ----------\n",
    "if len(df_oos_ar1):\n",
    "    df_val  = df_oos_ar1.loc[\"1983-01-01\":\"1989-12-31\"].copy()\n",
    "    df_test = df_oos_ar1.loc[\"1990-01-01\":\"2025-08-31\"].copy()\n",
    "\n",
    "    if len(df_val):\n",
    "        mae  = mean_absolute_error(df_val[\"y_true\"], df_val[\"y_hat\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df_val[\"y_true\"], df_val[\"y_hat\"]))\n",
    "        r2   = r2_score(df_val[\"y_true\"], df_val[\"y_hat\"]) if len(df_val) > 1 else np.nan\n",
    "        print(f\"\\nüìä Validation 83‚Äì89 ‚Äî n={len(df_val)} | MAE={mae:.3f} | RMSE={rmse:.3f} | R¬≤={r2:.3f}\")\n",
    "\n",
    "    if len(df_test):\n",
    "        mae  = mean_absolute_error(df_test[\"y_true\"], df_test[\"y_hat\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df_test[\"y_true\"], df_test[\"y_hat\"]))\n",
    "        r2   = r2_score(df_test[\"y_true\"], df_test[\"y_hat\"]) if len(df_test) > 1 else np.nan\n",
    "        print(f\"üìä Test 90‚Äì2025 ‚Äî n={len(df_test)} | MAE={mae:.3f} | RMSE={rmse:.3f} | R¬≤={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "389421de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Sauvegardes ----------\n",
    "AR1_LAST_PKL  = \"AR1_last_trained_model.pkl\"\n",
    "AR1_LAST_META = \"AR1_last_trained_model_meta.csv\"\n",
    "AR1_BUNDLE    = \"AR1_h12_oos_bundle.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc38f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Mod√®le AR(1) sauvegard√© ‚Üí AR1_last_trained_model.pkl\n",
      "üíæ Bundle AR(1) OOS sauvegard√© ‚Üí AR1_h12_oos_bundle.pkl\n",
      "üíæ M√©ta AR(1) sauvegard√©e ‚Üí AR1_last_trained_model_meta.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) mod√®le final\n",
    "if last_model is not None:\n",
    "    try:\n",
    "        joblib.dump(last_model, AR1_LAST_PKL)\n",
    "        print(f\"üíæ Mod√®le AR(1) sauvegard√© ‚Üí {AR1_LAST_PKL}\")\n",
    "    except Exception:\n",
    "        with open(AR1_LAST_PKL, \"wb\") as f:\n",
    "            pickle.dump(last_model, f)\n",
    "        print(f\"üíæ Mod√®le AR(1) sauvegard√© (pickle) ‚Üí {AR1_LAST_PKL}\")\n",
    "\n",
    "# 2) bundle des sorties\n",
    "bundle = {\n",
    "    \"oos_predictions\": (\n",
    "        df_oos_ar1.reset_index()\n",
    "                  .rename(columns={\"y_hat\": \"y_pred\"})\n",
    "                  .assign(date=lambda d: pd.to_datetime(d[\"date\"]).dt.to_period(\"M\").dt.to_timestamp(how=\"start\"))\n",
    "    ),\n",
    "    \"params\": {\n",
    "        \"model\": \"AR(1)\",\n",
    "        \"trend\": trend,\n",
    "        \"horizon\": h,\n",
    "        \"lag\": 1,\n",
    "        \"min_train_n\": min_train_n,\n",
    "        # ---- nouveaux champs ----\n",
    "        \"use_bagging\": bool(use_bagging),\n",
    "        \"B_boot\": int(B_boot),\n",
    "        \"L_block\": int(L_block)\n",
    "    },\n",
    "    \"meta\": {\n",
    "        \"trained_until\": str(last_fit_end.date()) if last_fit_end is not None else None,\n",
    "        \"index_freq\": \"MS\",\n",
    "        \"n_obs_y\": int(len(y)),\n",
    "        \"n_forecasts\": int(len(df_oos_ar1))\n",
    "    }\n",
    "}\n",
    "with open(AR1_BUNDLE, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "print(f\"üíæ Bundle AR(1) OOS sauvegard√© ‚Üí {AR1_BUNDLE}\")\n",
    "\n",
    "# 3) m√©ta csv\n",
    "meta_row = {\n",
    "    \"model\": \"AR(1)\",\n",
    "    \"trend\": trend,\n",
    "    \"lag\": 1,\n",
    "    \"trained_until\": str(last_fit_end.date()) if last_fit_end is not None else None,\n",
    "    \"n_obs_y\": int(len(y)),\n",
    "    \"n_forecasts\": int(len(df_oos_ar1))\n",
    "}\n",
    "pd.DataFrame([meta_row]).to_csv(AR1_LAST_META)\n",
    "print(f\"üíæ M√©ta AR(1) sauvegard√©e ‚Üí {AR1_LAST_META}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e2901",
   "metadata": {},
   "source": [
    "# 2. Autoregression en choisissant automatiquement l'ordre de p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbb0d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Param√®tres ----------\n",
    "h = 12\n",
    "min_train_n = 36          # ‚â• 3 ans\n",
    "trend = \"c\"               # \"c\" (constante) ou \"n\" (sans constante)\n",
    "p_grid = range(1, 13)     # p ‚àà {1,‚Ä¶,12}\n",
    "\n",
    "cv_update_every_months = 36\n",
    "cv_anchor = pd.Timestamp(\"1983-01-01\")\n",
    "\n",
    "# Bagging (comme les auteurs)\n",
    "use_bagging = True\n",
    "B_boot = 30               # n_boot ‚âà 30\n",
    "L_block = 12              # blocs de 12 mois (annuels)\n",
    "rng = np.random.default_rng(123)  # seed bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db1b45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Utils ----------\n",
    "def months_since(anchor, t):\n",
    "    return (t.year - anchor.year) * 12 + (t.month - anchor.month)\n",
    "\n",
    "def moving_block_bootstrap(arr, L, rng):\n",
    "    \"\"\"Concat√®ne des blocs contigus de taille L tir√©s al√©atoirement jusqu'√† n.\"\"\"\n",
    "    n = len(arr)\n",
    "    L = max(2, min(int(L), n-1))\n",
    "    nb = int(np.ceil(n / L))\n",
    "    starts = rng.integers(0, n - L + 1, size=nb)\n",
    "    out = np.concatenate([arr[s:s+L] for s in starts])[:n]\n",
    "    return out\n",
    "\n",
    "def rolling_mae_for_p(y_series, p, h, min_train, trend):\n",
    "    \"\"\"MAE rolling √† l'horizon h pour un p donn√© (sur y_series, en respectant l'ordre temporel).\"\"\"\n",
    "    rows = []\n",
    "    last_t_end = y_series.index.max() - relativedelta(months=h)\n",
    "    for t_end in y_series.index:\n",
    "        if t_end > last_t_end:\n",
    "            break\n",
    "        y_tr = y_series.loc[:t_end]\n",
    "        if len(y_tr) < max(min_train, p + 1):\n",
    "            continue\n",
    "        model = AutoReg(y_tr, lags=p, old_names=False, trend=trend).fit()\n",
    "        fc = model.predict(start=len(y_tr), end=len(y_tr) + h - 1)\n",
    "        yhat_h = float(fc.iloc[-1])\n",
    "        t_fore = t_end + relativedelta(months=h)\n",
    "        if t_fore in y_series.index:\n",
    "            rows.append((t_fore, yhat_h, float(y_series.loc[t_fore])))\n",
    "    if not rows:\n",
    "        return np.inf\n",
    "    tmp = pd.DataFrame(rows, columns=[\"date\", \"y_hat\", \"y_true\"]).set_index(\"date\")\n",
    "    return float(mean_absolute_error(tmp[\"y_true\"], tmp[\"y_hat\"]))\n",
    "\n",
    "def select_p_by_cv(y_tr, p_grid, h, min_train, trend):\n",
    "    \"\"\"S√©lectionne p* minimisant le MAE(h) rolling sur l'√©chantillon d'entra√Ænement courant.\"\"\"\n",
    "    best_p, best_score = None, np.inf\n",
    "    for p in p_grid:\n",
    "        score = rolling_mae_for_p(y_tr, p, h, min_train, trend)\n",
    "        if score < best_score:\n",
    "            best_score, best_p = score, p\n",
    "    return int(best_p if best_p is not None else 1)\n",
    "\n",
    "def bagged_h_forecast_ARp(y_tr, p, h, trend, B, L, rng):\n",
    "    \"\"\"\n",
    "    Pr√©vision √† horizon h via bagging (residual moving-block bootstrap) pour AR(p).\n",
    "    Retourne (yhat_mean, yhat_dist, base_pred).\n",
    "    \"\"\"\n",
    "    base = AutoReg(y_tr, lags=p, old_names=False, trend=trend).fit()\n",
    "    base_fc = base.predict(start=len(y_tr), end=len(y_tr)+h-1)\n",
    "    base_pred = float(base_fc.iloc[-1])\n",
    "\n",
    "    resid = base.resid.values\n",
    "    fitted = (y_tr.iloc[-len(resid):].values - resid)  # yÃÇ_t align√©\n",
    "\n",
    "    preds = []\n",
    "    for _ in range(B):\n",
    "        res_b = moving_block_bootstrap(resid, L, rng)\n",
    "        y_b = fitted + res_b\n",
    "        m_b = AutoReg(pd.Series(y_b, index=y_tr.index[-len(y_b):]),\n",
    "                      lags=p, old_names=False, trend=trend).fit()\n",
    "        fc_b = m_b.predict(start=len(y_tr), end=len(y_tr)+h-1)\n",
    "        preds.append(float(fc_b.iloc[-1]))\n",
    "    return float(np.mean(preds)), np.array(preds), base_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64ced83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] 1983-01-01 ‚Üí p* = 5\n",
      "[CV] 1986-01-01 ‚Üí p* = 4\n",
      "[CV] 1989-01-01 ‚Üí p* = 4\n",
      "[CV] 1992-01-01 ‚Üí p* = 4\n",
      "[CV] 1995-01-01 ‚Üí p* = 4\n",
      "[CV] 1998-01-01 ‚Üí p* = 4\n",
      "[CV] 2001-01-01 ‚Üí p* = 4\n",
      "[CV] 2004-01-01 ‚Üí p* = 4\n",
      "[CV] 2007-01-01 ‚Üí p* = 4\n",
      "[CV] 2010-01-01 ‚Üí p* = 4\n",
      "[CV] 2013-01-01 ‚Üí p* = 4\n",
      "[CV] 2016-01-01 ‚Üí p* = 4\n",
      "[CV] 2019-01-01 ‚Üí p* = 4\n",
      "[CV] 2022-01-01 ‚Üí p* = 4\n"
     ]
    }
   ],
   "source": [
    "# ---------- Boucle pseudo-OOS ----------\n",
    "rows = []\n",
    "last_model = None\n",
    "last_fit_end = None\n",
    "current_p = None\n",
    "\n",
    "last_t_end = y.index.max() - relativedelta(months=h)\n",
    "\n",
    "for t_end in y.index:\n",
    "    if t_end > last_t_end:\n",
    "        break\n",
    "\n",
    "    y_tr = y.loc[:t_end]\n",
    "    if len(y_tr) < min_train_n:\n",
    "        continue\n",
    "\n",
    "    # Re-CV √† partir de 1983-01 tous les 36 mois\n",
    "    if t_end >= cv_anchor:\n",
    "        m = months_since(cv_anchor, t_end)\n",
    "        need_cv = (m % cv_update_every_months == 0)\n",
    "    else:\n",
    "        need_cv = False\n",
    "\n",
    "    if current_p is None and not need_cv:\n",
    "        current_p = 1  # valeur initiale avant la premi√®re CV\n",
    "\n",
    "    if need_cv:\n",
    "        current_p = select_p_by_cv(y_tr, p_grid, h, min_train_n, trend)\n",
    "        print(f\"[CV] {t_end.date()} ‚Üí p* = {current_p}\")\n",
    "\n",
    "    # Fit de r√©f√©rence (utile pour meta/sauvegarde)\n",
    "    arp = AutoReg(y_tr, lags=current_p, old_names=False, trend=trend).fit()\n",
    "    last_model = arp\n",
    "    last_fit_end = t_end\n",
    "\n",
    "    # Pr√©vision √† h mois\n",
    "    if use_bagging:\n",
    "        # (Option) reseed par mois pour reproductibilit√© run-to-run :\n",
    "        # rng = np.random.default_rng(int(t_end.strftime(\"%Y%m\")))\n",
    "        yhat_h, yhat_dist, yhat_base = bagged_h_forecast_ARp(\n",
    "            y_tr=y_tr, p=current_p, h=h, trend=trend,\n",
    "            B=B_boot, L=L_block, rng=rng\n",
    "        )\n",
    "        yhat_p05 = float(np.percentile(yhat_dist, 5))\n",
    "        yhat_p95 = float(np.percentile(yhat_dist, 95))\n",
    "    else:\n",
    "        fc = arp.predict(start=len(y_tr), end=len(y_tr) + h - 1)\n",
    "        yhat_h = float(fc.iloc[-1])\n",
    "        yhat_base = yhat_h\n",
    "        yhat_p05 = np.nan\n",
    "        yhat_p95 = np.nan\n",
    "\n",
    "    t_fore = t_end + relativedelta(months=h)\n",
    "    if t_fore in y.index:\n",
    "        rows.append((t_fore, yhat_h, float(y.loc[t_fore]),\n",
    "                     int(current_p), yhat_p05, yhat_p95, yhat_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4702c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = 741\n",
      "               y_hat  y_true  p_used  y_hat_p05  y_hat_p95  y_hat_base\n",
      "date                                                                  \n",
      "1963-12-01  0.070473     0.0       1  -0.149798   0.286016   -0.080890\n",
      "1964-01-01  0.017682    -0.1       1  -0.194683   0.225812    0.141077\n",
      "1964-02-01  0.090722    -0.5       1  -0.050079   0.265508    0.408114\n",
      "\n",
      "üìä Validation 83‚Äì89 ‚Äî n=84 | MAE=0.819 | RMSE=1.187 | R¬≤=-0.805\n",
      "üìä Test 90‚Äì2025 ‚Äî n=428 | MAE=0.865 | RMSE=1.644 | R¬≤=-0.161\n"
     ]
    }
   ],
   "source": [
    "# ---------- R√©sultats ----------\n",
    "if rows:\n",
    "    df_oos_arp = (\n",
    "        pd.DataFrame(rows, columns=[\"date\",\"y_hat\",\"y_true\",\"p_used\",\"y_hat_p05\",\"y_hat_p95\",\"y_hat_base\"])\n",
    "          .set_index(\"date\").sort_index()\n",
    "    )\n",
    "else:\n",
    "    df_oos_arp = pd.DataFrame(columns=[\"y_hat\",\"y_true\",\"p_used\",\"y_hat_p05\",\"y_hat_p95\",\"y_hat_base\"])\n",
    "    df_oos_arp.index = pd.to_datetime(pd.Index([]))\n",
    "\n",
    "print(f\"\\n‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = {len(df_oos_arp)}\")\n",
    "print(df_oos_arp.head(3))\n",
    "\n",
    "# ---------- Scores par p√©riode ----------\n",
    "if len(df_oos_arp):\n",
    "    df_val  = df_oos_arp.loc[\"1983-01-01\":\"1989-12-31\"].copy()\n",
    "    df_test = df_oos_arp.loc[\"1990-01-01\":\"2025-08-31\"].copy()\n",
    "\n",
    "    if len(df_val):\n",
    "        mae  = mean_absolute_error(df_val[\"y_true\"], df_val[\"y_hat\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df_val[\"y_true\"], df_val[\"y_hat\"]))\n",
    "        r2   = r2_score(df_val[\"y_true\"], df_val[\"y_hat\"]) if len(df_val) > 1 else np.nan\n",
    "        print(f\"\\nüìä Validation 83‚Äì89 ‚Äî n={len(df_val)} | MAE={mae:.3f} | RMSE={rmse:.3f} | R¬≤={r2:.3f}\")\n",
    "\n",
    "    if len(df_test):\n",
    "        mae  = mean_absolute_error(df_test[\"y_true\"], df_test[\"y_hat\"])\n",
    "        rmse = np.sqrt(mean_squared_error(df_test[\"y_true\"], df_test[\"y_hat\"]))\n",
    "        r2   = r2_score(df_test[\"y_true\"], df_test[\"y_hat\"]) if len(df_test) > 1 else np.nan\n",
    "        print(f\"üìä Test 90‚Äì2025 ‚Äî n={len(df_test)} | MAE={mae:.3f} | RMSE={rmse:.3f} | R¬≤={r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad0a0e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Mod√®le AR(p) sauvegard√© ‚Üí ARp_last_trained_model.pkl\n",
      "üíæ Bundle AR(p) OOS sauvegard√© ‚Üí ARp_h12_oos_bundle.pkl\n",
      "üíæ M√©ta AR(p) sauvegard√©e ‚Üí ARp_last_trained_model_meta.csv\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Sauvegardes ‚Äî AR(p) bagging (h=12)\n",
    "# ==========================================\n",
    "ARP_LAST_PKL  = \"ARp_last_trained_model.pkl\"\n",
    "ARP_LAST_META = \"ARp_last_trained_model_meta.csv\"\n",
    "ARP_BUNDLE    = \"ARp_h12_oos_bundle.pkl\"\n",
    "\n",
    "# 1Ô∏è‚É£ Sauvegarde du mod√®le final (le dernier AR(p) entra√Æn√©)\n",
    "if last_model is not None:\n",
    "    try:\n",
    "        joblib.dump(last_model, ARP_LAST_PKL)\n",
    "        print(f\"üíæ Mod√®le AR(p) sauvegard√© ‚Üí {ARP_LAST_PKL}\")\n",
    "    except Exception:\n",
    "        with open(ARP_LAST_PKL, \"wb\") as f:\n",
    "            pickle.dump(last_model, f)\n",
    "        print(f\"üíæ Mod√®le AR(p) sauvegard√© (pickle) ‚Üí {ARP_LAST_PKL}\")\n",
    "\n",
    "# 2Ô∏è‚É£ Sauvegarde du bundle complet : pr√©visions + param√®tres + m√©tadonn√©es\n",
    "bundle = {\n",
    "    \"oos_predictions\": (\n",
    "        df_oos_arp.reset_index()\n",
    "                  .rename(columns={\"y_hat\": \"y_pred\"})\n",
    "                  .assign(date=lambda d: pd.to_datetime(d[\"date\"]).dt.to_period(\"M\").dt.to_timestamp(how=\"start\"))\n",
    "    ),\n",
    "    \"params\": {\n",
    "        \"model\": \"AR(p)\",\n",
    "        \"trend\": trend,\n",
    "        \"horizon\": h,\n",
    "        \"p_grid\": list(p_grid),\n",
    "        \"min_train_n\": min_train_n,\n",
    "        \"cv_update_every_months\": cv_update_every_months,\n",
    "        \"cv_anchor\": str(cv_anchor.date()),\n",
    "        # ---- param√®tres de bagging ----\n",
    "        \"use_bagging\": bool(use_bagging),\n",
    "        \"B_boot\": int(B_boot),\n",
    "        \"L_block\": int(L_block)\n",
    "    },\n",
    "    \"meta\": {\n",
    "        \"trained_until\": str(last_fit_end.date()) if last_fit_end is not None else None,\n",
    "        \"index_freq\": \"MS\",\n",
    "        \"n_obs_y\": int(len(y)),\n",
    "        \"n_forecasts\": int(len(df_oos_arp)),\n",
    "        \"mean_p_used\": float(df_oos_arp[\"p_used\"].mean()) if \"p_used\" in df_oos_arp else np.nan\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(ARP_BUNDLE, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "print(f\"üíæ Bundle AR(p) OOS sauvegard√© ‚Üí {ARP_BUNDLE}\")\n",
    "\n",
    "# 3Ô∏è‚É£ Sauvegarde d‚Äôun petit r√©sum√© m√©ta au format CSV\n",
    "meta_row = {\n",
    "    \"model\": \"AR(p)\",\n",
    "    \"trend\": trend,\n",
    "    \"horizon\": h,\n",
    "    \"cv_anchor\": str(cv_anchor.date()),\n",
    "    \"cv_update_months\": cv_update_every_months,\n",
    "    \"trained_until\": str(last_fit_end.date()) if last_fit_end is not None else None,\n",
    "    \"n_obs_y\": int(len(y)),\n",
    "    \"n_forecasts\": int(len(df_oos_arp)),\n",
    "    \"mean_p_used\": float(df_oos_arp[\"p_used\"].mean()) if \"p_used\" in df_oos_arp else np.nan\n",
    "}\n",
    "\n",
    "pd.DataFrame([meta_row]).to_csv(ARP_LAST_META, index=False)\n",
    "print(f\"üíæ M√©ta AR(p) sauvegard√©e ‚Üí {ARP_LAST_META}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d21c6",
   "metadata": {},
   "source": [
    "# 3. R√©gression lin√©aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ab3a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Param√®tres g√©n√©raux ----------\n",
    "h = 12\n",
    "min_train_n = 36           # ‚â• 3 ans avant de commencer √† pr√©voir\n",
    "winsor_level = 0.01        # winsorisation (1er/99e percentiles)\n",
    "norm_var = True            # normaliser ou non\n",
    "target_col = \"UNRATE\"      # cible dans df_stationary\n",
    "\n",
    "# Fen√™tres d'√©valuation / test\n",
    "eval_start = pd.Timestamp(\"1983-01-01\")\n",
    "eval_end   = pd.Timestamp(\"1989-12-31\")\n",
    "test_start = pd.Timestamp(\"1990-01-01\")\n",
    "test_end   = pd.Timestamp(\"2025-12-31\")   # ajuste si besoin\n",
    "\n",
    "# ---------- Bagging (bootstrap en blocs) ----------\n",
    "use_bagging = True\n",
    "B_boot = 30               # comme les auteurs\n",
    "L_block = 12              # blocs annuels (12 mois)\n",
    "rng = np.random.default_rng(123)  # seed bootstrap\n",
    "\n",
    "# ---------- Fichiers de sortie ----------\n",
    "LINREG_PKL  = \"linear_regression.pkl\"        # bundle (dict)\n",
    "LINREG_META = \"linear_regression_meta.csv\"   # m√©ta r√©sum√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0dfefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es pr√™tes : 1960-01-01 ‚Üí 2025-08-01 | n=788 | freq=MS\n",
      "Features (10): ['TB3MS', 'RPI', 'INDPRO', 'DPCERA3M086SBEA', 'S&P 500', 'BUSLOANS'] ...\n"
     ]
    }
   ],
   "source": [
    "# ---------- Pr√©paration df_stationary ----------\n",
    "def _ensure_ms_index(df):\n",
    "    \"\"\"Force un index DatetimeIndex en d√©but de mois (MS).\"\"\"\n",
    "    if \"date\" in df.columns:\n",
    "        df = df.set_index(\"date\")\n",
    "    idx = pd.to_datetime(df.index)\n",
    "    df = df.copy()\n",
    "    df.index = idx.to_period(\"M\").to_timestamp(how=\"start\")\n",
    "    return df.asfreq(\"MS\")\n",
    "\n",
    "# On part de df_stationary (toutes donn√©es : 1960‚Üí2025), d√©j√† charg√© en m√©moire\n",
    "df_all = _ensure_ms_index(df_stationary).sort_index()\n",
    "\n",
    "if target_col not in df_all.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' est absente de df_stationary.\")\n",
    "\n",
    "y_all = df_all[target_col].astype(float)\n",
    "X_all = df_all.drop(columns=[target_col]).astype(float)\n",
    "features = list(X_all.columns)\n",
    "\n",
    "print(f\"‚úÖ Donn√©es pr√™tes : {df_all.index.min().date()} ‚Üí {df_all.index.max().date()} | n={len(df_all)} | freq=MS\")\n",
    "print(f\"Features ({len(features)}): {features[:6]}{' ...' if len(features)>6 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ed7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pr√©proc ----------\n",
    "def fit_preproc(X, wins=0.01, do_norm=True):\n",
    "    \"\"\"Apprend winsor + normalisation sur TRAIN et renvoie (X_trans, prep).\"\"\"\n",
    "    lower = X.quantile(wins)\n",
    "    upper = X.quantile(1 - wins)\n",
    "    Xw = X.clip(lower=lower, upper=upper, axis=1)\n",
    "    if do_norm:\n",
    "        mean = Xw.mean()\n",
    "        std  = Xw.std().replace(0, 1)\n",
    "        Xn   = (Xw - mean) / std\n",
    "        prep = {\"lower\": lower, \"upper\": upper, \"mean\": mean, \"std\": std, \"norm\": True}\n",
    "        return Xn, prep\n",
    "    else:\n",
    "        prep = {\"lower\": lower, \"upper\": upper, \"mean\": None, \"std\": None, \"norm\": False}\n",
    "        return Xw, prep\n",
    "\n",
    "def apply_preproc(X, prep):\n",
    "    \"\"\"Applique le pr√©proc appris (pas de fuite).\"\"\"\n",
    "    Xp = X.clip(lower=prep[\"lower\"], upper=prep[\"upper\"], axis=1)\n",
    "    if prep[\"norm\"]:\n",
    "        Xp = (Xp - prep[\"mean\"]) / prep[\"std\"].replace(0, 1)\n",
    "    return Xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a6ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Bootstrap utils ----------\n",
    "def block_bootstrap_rows(index, L, rng):\n",
    "    \"\"\"\n",
    "    Moving-block bootstrap sur index (positions).\n",
    "    Renvoie un array d'indices (longueur = n).\n",
    "    \"\"\"\n",
    "    n = len(index)\n",
    "    if n < 3:\n",
    "        return np.arange(n)  # fallback\n",
    "    L = max(2, min(int(L), n-1))\n",
    "    nb = int(np.ceil(n / L))\n",
    "    starts = rng.integers(0, n - L + 1, size=nb)\n",
    "    ix = np.concatenate([np.arange(s, s+L) for s in starts])[:n]\n",
    "    return ix\n",
    "\n",
    "def bagged_predict_linreg(X_tr_raw, y_tr, x_fore_raw, prep, B, L, rng):\n",
    "    \"\"\"\n",
    "    Bagging (moving-block bootstrap) pour LinearRegression :\n",
    "      - pr√©proc fix√© sur TRAIN original (pas r√©-appris)\n",
    "      - r√©√©chantillon par blocs (lignes) (X, y)\n",
    "      - fit et pr√©diction h\n",
    "      - renvoie (moyenne, distribution compl√®te, base_pred)\n",
    "    \"\"\"\n",
    "    # Base fit (r√©f√©rence)\n",
    "    X_tr_p = apply_preproc(X_tr_raw, prep)\n",
    "    base = LinearRegression()\n",
    "    base.fit(X_tr_p, y_tr.values)\n",
    "    yhat_base = float(base.predict(apply_preproc(x_fore_raw, prep))[0])\n",
    "\n",
    "    preds = []\n",
    "    for _ in range(B):\n",
    "        ix = block_bootstrap_rows(X_tr_raw.index, L, rng)\n",
    "        Xb = X_tr_raw.iloc[ix]\n",
    "        yb = y_tr.iloc[ix]\n",
    "        Xb_p = apply_preproc(Xb, prep)  # IMPORTANT: m√™me prep\n",
    "        m = LinearRegression()\n",
    "        m.fit(Xb_p, yb.values)\n",
    "        preds.append(float(m.predict(apply_preproc(x_fore_raw, prep))[0]))\n",
    "    return float(np.mean(preds)), np.array(preds), yhat_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81982235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Boucle pseudo-OOS ----------\n",
    "rows = []                 # (date, y_pred, y_true, y_pred_base, p05, p95)\n",
    "models = []               # stockage dernier fit (optionnel)\n",
    "preprocs = []             # stockage prep (optionnel)\n",
    "train_ends = []           # dates de fin train (pour trace)\n",
    "\n",
    "last_t_end = y_all.index.max() - relativedelta(months=h)\n",
    "last_model = None\n",
    "last_fit_end = None\n",
    "\n",
    "for t_end in y_all.index:\n",
    "    if t_end > last_t_end:\n",
    "        break\n",
    "\n",
    "    y_tr = y_all.loc[:t_end]\n",
    "    X_tr = X_all.loc[:t_end]\n",
    "    if len(y_tr) < min_train_n:\n",
    "        continue\n",
    "\n",
    "    # Pr√©proc appris sur TRAIN courant\n",
    "    X_tr_p, prep = fit_preproc(X_tr, wins=winsor_level, do_norm=norm_var)\n",
    "\n",
    "    # Horizon cibl√©\n",
    "    t_fore = t_end + relativedelta(months=h)\n",
    "    if t_fore in y_all.index:\n",
    "        x_fore_raw = X_all.loc[[t_fore]]\n",
    "\n",
    "        if use_bagging:\n",
    "            # (Option) reseed par mois : rng = np.random.default_rng(int(t_end.strftime(\"%Y%m\")))\n",
    "            yhat_h, dist, yhat_base = bagged_predict_linreg(\n",
    "                X_tr_raw=X_tr, y_tr=y_tr, x_fore_raw=x_fore_raw,\n",
    "                prep=prep, B=B_boot, L=L_block, rng=rng\n",
    "            )\n",
    "            y_p05 = float(np.percentile(dist, 5))\n",
    "            y_p95 = float(np.percentile(dist, 95))\n",
    "        else:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_tr_p, y_tr.values)\n",
    "            yhat_h = float(model.predict(apply_preproc(x_fore_raw, prep))[0])\n",
    "            yhat_base = yhat_h\n",
    "            y_p05, y_p95 = (np.nan, np.nan)\n",
    "\n",
    "        rows.append((t_fore, yhat_h, float(y_all.loc[t_fore]), yhat_base, y_p05, y_p95))\n",
    "\n",
    "    # trace / dernier mod√®le base (utile pour sauvegarde)\n",
    "    last_model = LinearRegression().fit(X_tr_p, y_tr.values)\n",
    "    last_fit_end = t_end\n",
    "    models.append(last_model)\n",
    "    preprocs.append(prep)\n",
    "    train_ends.append(t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56ab795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = 741\n",
      "              y_pred  y_true  y_pred_base  y_pred_p05  y_pred_p95\n",
      "date                                                             \n",
      "1963-12-01 -0.729972     0.0    -0.354113   -1.487587   -0.177087\n",
      "1964-01-01 -0.234660    -0.1    -0.282896   -1.125836    0.670996\n",
      "1964-02-01  1.067340    -0.5     1.105841   -0.124761    2.173422\n",
      "\n",
      "üìä Validation 83‚Äì89 ‚Äî n=84 | MAE=0.815 | RMSE=1.024 | R¬≤=-0.342\n",
      "üìä Test 90‚Äì2025 ‚Äî n=428 | MAE=0.832 | RMSE=1.480 | R¬≤=0.059\n",
      "‚û°Ô∏è  Gain bagging (ŒîMAE) = -0.012\n"
     ]
    }
   ],
   "source": [
    "# ---------- DataFrame OOS ----------\n",
    "if rows:\n",
    "    df_oos = (\n",
    "        pd.DataFrame(rows, columns=[\"date\", \"y_pred\", \"y_true\", \"y_pred_base\", \"y_pred_p05\", \"y_pred_p95\"])\n",
    "          .assign(date=lambda d: pd.to_datetime(d[\"date\"]).dt.to_period(\"M\").dt.to_timestamp(how=\"start\"))\n",
    "          .set_index(\"date\").sort_index()\n",
    "    )\n",
    "else:\n",
    "    df_oos = pd.DataFrame(columns=[\"y_pred\", \"y_true\", \"y_pred_base\", \"y_pred_p05\", \"y_pred_p95\"])\n",
    "    df_oos.index = pd.to_datetime(pd.Index([]))\n",
    "\n",
    "print(f\"\\n‚úÖ Pseudo-OOS termin√© ‚Äî n pr√©visions = {len(df_oos)}\")\n",
    "print(df_oos.head(3))\n",
    "\n",
    "# ---------- Scores ----------\n",
    "def _scores(df):\n",
    "    if len(df) == 0:\n",
    "        return {\"MAE\": np.nan, \"RMSE\": np.nan, \"R2\": np.nan}\n",
    "    mae  = mean_absolute_error(df[\"y_true\"], df[\"y_pred\"])\n",
    "    rmse = np.sqrt(mean_squared_error(df[\"y_true\"], df[\"y_pred\"]))\n",
    "    r2   = r2_score(df[\"y_true\"], df[\"y_pred\"]) if len(df) > 1 else np.nan\n",
    "    return {\"MAE\": float(mae), \"RMSE\": float(rmse), \"R2\": float(r2)}\n",
    "\n",
    "df_val  = df_oos.loc[eval_start:eval_end].copy()\n",
    "df_test = df_oos.loc[test_start:test_end].copy()\n",
    "\n",
    "sc_val  = _scores(df_val)\n",
    "sc_test = _scores(df_test)\n",
    "\n",
    "print(f\"\\nüìä Validation 83‚Äì89 ‚Äî n={len(df_val)} | MAE={sc_val['MAE']:.3f} | RMSE={sc_val['RMSE']:.3f} | R¬≤={sc_val['R2']:.3f}\")\n",
    "print(f\"üìä Test 90‚Äì2025 ‚Äî n={len(df_test)} | MAE={sc_test['MAE']:.3f} | RMSE={sc_test['RMSE']:.3f} | R¬≤={sc_test['R2']:.3f}\")\n",
    "\n",
    "# (option) Comparaison bagging vs base\n",
    "if \"y_pred_base\" in df_oos and df_oos[\"y_pred_base\"].notna().any():\n",
    "    mae_bag  = mean_absolute_error(df_oos[\"y_true\"], df_oos[\"y_pred\"])\n",
    "    mae_base = mean_absolute_error(df_oos[\"y_true\"], df_oos[\"y_pred_base\"])\n",
    "    print(f\"‚û°Ô∏è  Gain bagging (ŒîMAE) = {mae_base - mae_bag:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8e1405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Bundle sauvegard√© ‚Üí linear_regression.pkl\n",
      "üíæ M√©ta sauvegard√©e ‚Üí linear_regression_meta.csv\n",
      "üì¶ Contenu du bundle : ['oos_predictions', 'params', 'meta', 'train_fit_dates', 'models', 'preprocs']\n"
     ]
    }
   ],
   "source": [
    "# ---------- Sauvegardes ----------\n",
    "bundle = {\n",
    "    \"oos_predictions\": df_oos.reset_index(),     # (date, y_pred, y_true, y_pred_base, y_pred_p05, y_pred_p95)\n",
    "    \"params\": {\n",
    "        \"model\": \"LinearRegression\",\n",
    "        \"horizon\": h,\n",
    "        \"min_train_n\": min_train_n,\n",
    "        \"winsor_level\": winsor_level,\n",
    "        \"norm_var\": norm_var,\n",
    "        \"features\": features,\n",
    "        \"eval_window\": (str(eval_start.date()), str(eval_end.date())),\n",
    "        \"test_window\": (str(test_start.date()), str(test_end.date())),\n",
    "        # ---- bagging ----\n",
    "        \"use_bagging\": bool(use_bagging),\n",
    "        \"B_boot\": int(B_boot),\n",
    "        \"L_block\": int(L_block),\n",
    "    },\n",
    "    \"meta\": {\n",
    "        \"trained_until\": str(last_fit_end.date()) if last_fit_end is not None else None,\n",
    "        \"index_freq\": \"MS\",\n",
    "        \"n_obs_all\": int(len(df_all)),\n",
    "        \"n_forecasts\": int(len(df_oos)),\n",
    "    },\n",
    "    \"train_fit_dates\": pd.to_datetime(pd.Index(train_ends)),\n",
    "\n",
    "    # üîªüîªüîª AJOUT ESSENTIEL POUR LA PERMUTATION üîªüîªüîª\n",
    "    \"models\":   models,     # liste des mod√®les LinearRegression (un par fen√™tre)\n",
    "    \"preprocs\": preprocs,   # liste des pr√©proc (dict) align√©s aux mod√®les\n",
    "    # üî∫üî∫üî∫\n",
    "}\n",
    "\n",
    "# --- Sauvegarde du bundle complet ---\n",
    "with open(LINREG_PKL, \"wb\") as f:\n",
    "    pickle.dump(bundle, f)\n",
    "\n",
    "# --- Sauvegarde du r√©sum√© m√©ta s√©par√© (lisible rapidement) ---\n",
    "pd.DataFrame([{\n",
    "    \"model\": \"LinearRegression\",\n",
    "    \"horizon\": h,\n",
    "    \"min_train_n\": min_train_n,\n",
    "    \"winsor_level\": winsor_level,\n",
    "    \"norm_var\": norm_var,\n",
    "    \"use_bagging\": bool(use_bagging),\n",
    "    \"B_boot\": int(B_boot),\n",
    "    \"L_block\": int(L_block),\n",
    "    \"trained_until\": bundle[\"meta\"][\"trained_until\"],\n",
    "    \"n_forecasts\": bundle[\"meta\"][\"n_forecasts\"],\n",
    "}]).to_csv(LINREG_META, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Bundle sauvegard√© ‚Üí {LINREG_PKL}\")\n",
    "print(f\"üíæ M√©ta sauvegard√©e ‚Üí {LINREG_META}\")\n",
    "print(f\"üì¶ Contenu du bundle : {list(bundle.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
