{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2478ba5b",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41027a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import shap\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.utils import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22973a6a",
   "metadata": {},
   "source": [
    "# Importation des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedcdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary_train = pd.read_csv(\"df_stationary_train.csv\", index_col=\"date\")\n",
    "df_stationary_test = pd.read_csv(\"df_stationary_test.csv\", index_col=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91223b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>TB3MS</th>\n",
       "      <th>RPI</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>S&amp;P 500</th>\n",
       "      <th>BUSLOANS</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>OILPRICEx</th>\n",
       "      <th>M2SL</th>\n",
       "      <th>USREC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960-01-01</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.091980</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>-0.006156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-02-01</th>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.076964</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>-0.025663</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-03-01</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>-0.070857</td>\n",
       "      <td>-0.008356</td>\n",
       "      <td>-0.005455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-04-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>-0.025915</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>-0.040442</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.007747</td>\n",
       "      <td>-0.018121</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>-0.010090</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            UNRATE  TB3MS       RPI    INDPRO  DPCERA3M086SBEA   S&P 500  \\\n",
       "date                                                                       \n",
       "1960-01-01    -0.8   0.30  0.020977  0.091980         0.001204  0.017909   \n",
       "1960-02-01    -1.1  -0.19  0.014565  0.076964         0.006009 -0.025663   \n",
       "1960-03-01    -0.2  -1.18  0.006250  0.007961         0.021240 -0.070857   \n",
       "1960-04-01     0.0  -1.12  0.006489 -0.025915         0.033752 -0.040442   \n",
       "1960-05-01     0.0  -0.67  0.007747 -0.018121         0.009040 -0.010090   \n",
       "\n",
       "            BUSLOANS  CPIAUCSL  OILPRICEx      M2SL  USREC  \n",
       "date                                                        \n",
       "1960-01-01  0.011578 -0.006156        0.0  0.001323      0  \n",
       "1960-02-01  0.011905 -0.003767        0.0  0.002007      0  \n",
       "1960-03-01 -0.008356 -0.005455        0.0  0.001324      0  \n",
       "1960-04-01 -0.009098  0.005090        0.0  0.000634      1  \n",
       "1960-05-01 -0.000359  0.003383        0.0  0.003977      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stationary_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aff52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary_train.index = pd.to_datetime(df_stationary_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58729f82",
   "metadata": {},
   "source": [
    "# stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c1c02",
   "metadata": {},
   "source": [
    "# 1) Param√®tres & sous-ensemble TRAIN global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081d728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# ---------- Param√®tres ----------\n",
    "h = 12                     # horizon de pr√©vision (mois)\n",
    "step_size = 12             # refit annuel\n",
    "winsor_level = 0.01\n",
    "df_full = df_stationary_train.copy()  # index mensuel tri√©\n",
    "df_train_global = df_full.loc[\"1960-01\":\"1989-12\"].copy()\n",
    "\n",
    "# ‚úÖ Inclure toutes les features (aucune exclusion)\n",
    "cols_tx = [c for c in df_train_global.columns if c != \"UNRATE\"]\n",
    "\n",
    "# ---------- Containers ----------\n",
    "models = []\n",
    "coefs = []\n",
    "intercepts = []\n",
    "train_periods = []\n",
    "forecast_records = []  # (origin, target, y_true, y_hat, n_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "195f861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01] Fin 1961-12 | train=12 | yÃÇ(1962-12) = 2.466\n",
      "[02] Fin 1962-12 | train=24 | yÃÇ(1963-12) = -0.489\n",
      "[03] Fin 1963-12 | train=36 | yÃÇ(1964-12) = -0.571\n",
      "[04] Fin 1964-12 | train=48 | yÃÇ(1965-12) = -0.928\n",
      "[05] Fin 1965-12 | train=60 | yÃÇ(1966-12) = -0.478\n",
      "[06] Fin 1966-12 | train=72 | yÃÇ(1967-12) = -0.412\n",
      "[07] Fin 1967-12 | train=84 | yÃÇ(1968-12) = -0.704\n",
      "[08] Fin 1968-12 | train=96 | yÃÇ(1969-12) = -0.869\n",
      "[09] Fin 1969-12 | train=108 | yÃÇ(1970-12) = 0.650\n",
      "[10] Fin 1970-12 | train=120 | yÃÇ(1971-12) = 0.780\n",
      "[11] Fin 1971-12 | train=132 | yÃÇ(1972-12) = -0.210\n",
      "[12] Fin 1972-12 | train=144 | yÃÇ(1973-12) = -0.908\n",
      "[13] Fin 1973-12 | train=156 | yÃÇ(1974-12) = 1.567\n",
      "[14] Fin 1974-12 | train=168 | yÃÇ(1975-12) = 2.097\n",
      "[15] Fin 1975-12 | train=180 | yÃÇ(1976-12) = -0.305\n",
      "[16] Fin 1976-12 | train=192 | yÃÇ(1977-12) = -0.194\n",
      "[17] Fin 1977-12 | train=204 | yÃÇ(1978-12) = -0.156\n",
      "[18] Fin 1978-12 | train=216 | yÃÇ(1979-12) = 0.318\n",
      "[19] Fin 1979-12 | train=228 | yÃÇ(1980-12) = 0.462\n",
      "[20] Fin 1980-12 | train=240 | yÃÇ(1981-12) = -0.153\n",
      "[21] Fin 1981-12 | train=252 | yÃÇ(1982-12) = 0.133\n",
      "[22] Fin 1982-12 | train=264 | yÃÇ(1983-12) = -0.859\n",
      "[23] Fin 1983-12 | train=276 | yÃÇ(1984-12) = -0.450\n",
      "[24] Fin 1984-12 | train=288 | yÃÇ(1985-12) = -0.985\n",
      "[25] Fin 1985-12 | train=300 | yÃÇ(1986-12) = -0.994\n",
      "[26] Fin 1986-12 | train=312 | yÃÇ(1987-12) = -0.011\n",
      "[27] Fin 1987-12 | train=324 | yÃÇ(1988-12) = 0.247\n",
      "[28] Fin 1988-12 | train=336 | yÃÇ(1989-12) = 0.087\n",
      "[29] Fin 1989-12 | train=348 | yÃÇ(NA) = -0.103\n"
     ]
    }
   ],
   "source": [
    "# ---------- Boucle EXPANDING WINDOW ----------\n",
    "n_total = len(df_train_global)\n",
    "for t, end in enumerate(range(step_size, n_total + 1, step_size)):\n",
    "    df_train_local = df_train_global.iloc[:end].copy()   # ‚úÖ corrige .iloc et .copy()\n",
    "\n",
    "    # Assez d'obs pour aligner X_t avec Y_{t+h} ?\n",
    "    if len(df_train_local) <= h:\n",
    "        continue\n",
    "\n",
    "    # X_train : jusqu'√† t_end - h ; Y_train : UNRATE d√©cal√© de -h sur la m√™me plage\n",
    "    X_train = df_train_local[cols_tx].iloc[:-h].copy()\n",
    "    Y_train = df_train_local[\"UNRATE\"].shift(-h).iloc[:-h].copy()\n",
    "\n",
    "    # Retire lignes avec NaN √©ventuels\n",
    "    valid = ~(X_train.isnull().any(axis=1) | Y_train.isnull())\n",
    "    X_train = X_train.loc[valid]\n",
    "    Y_train = Y_train.loc[valid]\n",
    "\n",
    "    # 1Ô∏è‚É£ Winsorisation (1% - 99%) apprise sur la fen√™tre courante\n",
    "    lower_wins = X_train.quantile(winsor_level)\n",
    "    upper_wins = X_train.quantile(1 - winsor_level)\n",
    "    Xw = X_train.clip(lower=lower_wins, upper=upper_wins, axis=1)\n",
    "\n",
    "    # 2Ô∏è‚É£ Normalisation (toujours activ√©e)\n",
    "    mean_train = Xw.mean()\n",
    "    std_train = Xw.std().replace(0, 1)\n",
    "    Xs = (Xw - mean_train) / std_train\n",
    "\n",
    "    # 3Ô∏è‚É£ Entra√Ænement OLS\n",
    "    model = LinearRegression()\n",
    "    model.fit(Xs, Y_train)\n",
    "\n",
    "    # 4Ô∏è‚É£ Pr√©vision pseudo-OOS √† l'origine t_end : yÃÇ_{t_end+h}\n",
    "    #    -> on prend la derni√®re observation dispo (t_end) c√¥t√© X\n",
    "    x_origin = df_train_local[cols_tx].iloc[[-1]].copy()\n",
    "    x_origin_w = x_origin.clip(lower=lower_wins, upper=upper_wins, axis=1)\n",
    "    x_origin_s = (x_origin_w - mean_train) / std_train\n",
    "    y_hat = float(model.predict(x_origin_s)[0])\n",
    "\n",
    "    origin_date = df_train_local.index[-1]\n",
    "    # date cible = origin + h si dispo dans df_full\n",
    "    idx_origin = df_full.index.get_loc(origin_date)\n",
    "    target_date = df_full.index[idx_origin + h] if idx_origin + h < len(df_full) else pd.NaT\n",
    "    y_true = float(df_full.loc[target_date, \"UNRATE\"]) if pd.notna(target_date) else np.nan\n",
    "\n",
    "    # 5Ô∏è‚É£ Sauvegarde\n",
    "    models.append(model)\n",
    "    coefs.append(pd.Series(model.coef_, index=cols_tx))\n",
    "    intercepts.append(model.intercept_)\n",
    "    train_periods.append(origin_date)\n",
    "    forecast_records.append({\n",
    "        \"origin\": origin_date, \"target\": target_date,\n",
    "        \"y_true\": y_true, \"y_hat\": y_hat, \"n_train\": len(Xs)\n",
    "    })\n",
    "\n",
    "    print(f\"[{t:02d}] Fin {origin_date.strftime('%Y-%m')} | train={len(Xs)} | \"\n",
    "          f\"yÃÇ({('NA' if pd.isna(target_date) else target_date.strftime('%Y-%m'))}) = {y_hat:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6836860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for t, end in enumerate(range(step_size, n_total + 1, step_size)):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd2fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== √âVALUATION PSEUDO‚ÄìOOS (h = 12 mois) ===\n",
      "R¬≤            : 0.095\n",
      "R¬≤ (origin)   : 0.205\n",
      "MAE           : 0.809\n",
      "RMSE          : 1.058\n",
      "Corr(y, yÃÇ)   : 0.453  (p=0.0154)\n",
      "Hit rate sign : 0.714\n",
      "AMD (|bias|)  : 0.010\n",
      "\n",
      "--- Benchmark na√Øf (z√©ro-changement) ---\n",
      "MAE_na√Øf0     : 0.800\n",
      "RMSE_na√Øf0    : 1.113\n",
      "\n",
      "--- MAE/RMSE par d√©cennie ---\n",
      " decade    n      MAE     RMSE\n",
      "   1960  8.0 0.695125 1.136080\n",
      "   1970 10.0 0.772075 0.930614\n",
      "   1980 10.0 0.937675 1.112530\n",
      "\n",
      "‚úÖ √âvaluation termin√©e. R√©sultats enregistr√©s dans eval_results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mita\\AppData\\Local\\Temp\\ipykernel_14108\\1481986021.py:60: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# ===================== √âVALUATION PSEUDO‚ÄìOUT-OF-SAMPLE =====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1Ô∏è‚É£ Rassembler les pr√©visions\n",
    "forecast_df = pd.DataFrame(forecast_records).dropna(subset=[\"y_true\", \"y_hat\"]).copy()\n",
    "forecast_df = forecast_df.sort_values(\"target\").reset_index(drop=True)\n",
    "\n",
    "def r2_origin_reg(y, yhat):\n",
    "    \"\"\"R¬≤ d'une r√©gression √† l‚Äôorigine: y ‚âà b * yhat (sans intercept).\"\"\"\n",
    "    denom = np.dot(yhat, yhat)\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    b = np.dot(yhat, y) / denom\n",
    "    sse = np.sum((y - b * yhat) ** 2)\n",
    "    sst = np.sum((y - y.mean()) ** 2)\n",
    "    return 1 - sse / sst if sst > 0 else np.nan\n",
    "\n",
    "def corr_pvalue(y, yhat):\n",
    "    if len(y) < 3:\n",
    "        return np.nan, np.nan\n",
    "    r, p = pearsonr(y, yhat)\n",
    "    return float(r), float(p)\n",
    "\n",
    "if forecast_df.empty:\n",
    "    print(\"\\n[√âVALUATION] Aucune pr√©vision disponible (forecast_df est vide).\")\n",
    "else:\n",
    "    y = forecast_df[\"y_true\"].values\n",
    "    yhat = forecast_df[\"y_hat\"].values\n",
    "\n",
    "    # 2Ô∏è‚É£ M√©triques principales\n",
    "    r2   = r2_score(y, yhat)\n",
    "    mae  = mean_absolute_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))   # ‚úÖ compatible toutes versions\n",
    "    r2_o = r2_origin_reg(y, yhat)\n",
    "    corr, pval = corr_pvalue(y, yhat)\n",
    "    amd  = float(abs(np.mean(y - yhat)))          # biais absolu moyen\n",
    "\n",
    "    # 3Ô∏è‚É£ Benchmark na√Øf (utile si la cible est Œî12 UNRATE)\n",
    "    yhat_naive0 = np.zeros_like(y)\n",
    "    mae_naive0  = mean_absolute_error(y, yhat_naive0)\n",
    "    rmse_naive0 = np.sqrt(mean_squared_error(y, yhat_naive0))\n",
    "\n",
    "    # 4Ô∏è‚É£ Pr√©cision directionnelle\n",
    "    hit_rate = float(np.mean(np.sign(y) == np.sign(yhat))) if len(y) > 0 else np.nan\n",
    "\n",
    "    # 5Ô∏è‚É£ Calibration (Mincer‚ÄìZarnowitz): y = a + b * yhat\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(yhat.reshape(-1, 1), y)\n",
    "    a_calib = float(reg.intercept_)\n",
    "    b_calib = float(reg.coef_[0])\n",
    "\n",
    "    # 6Ô∏è‚É£ R√©sum√© par d√©cennie (facultatif)\n",
    "    by_decade = (\n",
    "        forecast_df.assign(decade=forecast_df[\"target\"].dt.year // 10 * 10)\n",
    "                   .groupby(\"decade\")\n",
    "                   .apply(lambda g: pd.Series({\n",
    "                       \"n\": len(g),\n",
    "                       \"MAE\": mean_absolute_error(g[\"y_true\"], g[\"y_hat\"]),\n",
    "                       \"RMSE\": np.sqrt(mean_squared_error(g[\"y_true\"], g[\"y_hat\"]))\n",
    "                   }))\n",
    "                   .reset_index()\n",
    "    )\n",
    "\n",
    "    # 7Ô∏è‚É£ Impression des r√©sultats\n",
    "    print(\"\\n=== √âVALUATION PSEUDO‚ÄìOOS (h = {} mois) ===\".format(h))\n",
    "    print(f\"R¬≤            : {r2:.3f}\")\n",
    "    print(f\"R¬≤ (origin)   : {r2_o:.3f}\")\n",
    "    print(f\"MAE           : {mae:.3f}\")\n",
    "    print(f\"RMSE          : {rmse:.3f}\")\n",
    "    print(f\"Corr(y, yÃÇ)   : {corr:.3f}  (p={pval:.3g})\")\n",
    "    print(f\"Hit rate sign : {hit_rate:.3f}\")\n",
    "    print(f\"AMD (|bias|)  : {amd:.3f}\")\n",
    "\n",
    "    print(\"\\n--- Benchmark na√Øf (z√©ro-changement) ---\")\n",
    "    print(f\"MAE_na√Øf0     : {mae_naive0:.3f}\")\n",
    "    print(f\"RMSE_na√Øf0    : {rmse_naive0:.3f}\")\n",
    "\n",
    "    if not by_decade.empty:\n",
    "        print(\"\\n--- MAE/RMSE par d√©cennie ---\")\n",
    "        print(by_decade.to_string(index=False))\n",
    "\n",
    "    # 8Ô∏è‚É£ Sauvegarde des r√©sultats\n",
    "    eval_results = {\n",
    "        \"overall\": {\n",
    "            \"r2\": r2, \"r2_origin\": r2_o, \"mae\": mae, \"rmse\": rmse,\n",
    "            \"corr\": corr, \"pval\": pval, \"hit_rate\": hit_rate, \"amd\": amd\n",
    "        },\n",
    "        \"benchmark_naive0\": {\n",
    "            \"mae\": mae_naive0, \"rmse\": rmse_naive0\n",
    "        },\n",
    "        \"calibration\": {\n",
    "            \"intercept\": a_calib, \"slope\": b_calib\n",
    "        },\n",
    "        \"by_decade\": by_decade,\n",
    "        \"forecast_df\": forecast_df\n",
    "    }\n",
    "\n",
    "    print(\"\\n‚úÖ √âvaluation termin√©e. R√©sultats enregistr√©s dans eval_results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad858c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# üîç IMPORTANCE PAR PERMUTATION ‚Äî PSEUDO-OOS\n",
    "# ==========================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def permutation_importance_pseudo_oos(models, df_train_global, cols_tx, h=12, n_repeats=20, metric=mean_absolute_error):\n",
    "    \"\"\"\n",
    "    Importance par permutation pour une s√©rie de mod√®les OLS entra√Æn√©s\n",
    "    selon une logique expanding window pseudo‚ÄìOOS.\n",
    "    -> aucune r√©estimation\n",
    "    -> mesure la d√©gradation moyenne de la performance apr√®s permutation de chaque variable\n",
    "    \"\"\"\n",
    "    var_imp = {col: [] for col in cols_tx}\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        # Reconstituer la fen√™tre utilis√©e par le mod√®le i\n",
    "        end_idx = (i + 1) * 12  # correspond √† ton step_size = 12\n",
    "        df_win = df_train_global.iloc[:end_idx].copy()\n",
    "\n",
    "        if len(df_win) <= h:\n",
    "            continue\n",
    "\n",
    "        # Pr√©paration des donn√©es (alignement X_t avec Y_{t+h})\n",
    "        X = df_win[cols_tx].iloc[:-h].copy()\n",
    "        y = df_win[\"UNRATE\"].shift(-h).iloc[:-h].copy()\n",
    "        valid = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "        X, y = X.loc[valid], y.loc[valid]\n",
    "\n",
    "        # Score de base (MAE sur donn√©es d'origine)\n",
    "        base_score = metric(y, model.predict(X))\n",
    "\n",
    "        # Boucle sur chaque variable\n",
    "        for col in cols_tx:\n",
    "            perm_scores = []\n",
    "            for _ in range(n_repeats):\n",
    "                X_perm = X.copy()\n",
    "                X_perm[col] = np.random.permutation(X_perm[col])\n",
    "                perm_scores.append(metric(y, model.predict(X_perm)))\n",
    "            perm_scores = np.array(perm_scores)\n",
    "            var_imp[col].append(np.mean(perm_scores) / base_score)\n",
    "\n",
    "    # Agr√©gation moyenne sur toutes les fen√™tres\n",
    "    results = []\n",
    "    for col, ratios in var_imp.items():\n",
    "        if len(ratios) > 0:\n",
    "            results.append({\n",
    "                \"variable\": col,\n",
    "                \"perm_mae_ratio_mean\": np.mean(ratios),\n",
    "                \"perm_mae_ratio_std\": np.std(ratios),\n",
    "                \"n_windows\": len(ratios)\n",
    "            })\n",
    "\n",
    "    imp_df = pd.DataFrame(results).sort_values(\"perm_mae_ratio_mean\", ascending=False).reset_index(drop=True)\n",
    "    return imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa54405b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üîç Importance par permutation (pseudo‚ÄìOOS) ===\n",
      "       variable  perm_mae_ratio_mean  perm_mae_ratio_std  n_windows\n",
      "          USREC             1.089988            0.055342         28\n",
      "          TB3MS             1.028684            0.025290         28\n",
      "        S&P 500             1.013657            0.004299         28\n",
      "      OILPRICEx             1.004552            0.004326         28\n",
      "DPCERA3M086SBEA             1.000241            0.000357         28\n",
      "           M2SL             1.000235            0.000371         28\n",
      "            RPI             1.000066            0.000359         28\n",
      "       BUSLOANS             1.000058            0.000205         28\n",
      "         INDPRO             1.000039            0.002126         28\n",
      "       CPIAUCSL             1.000038            0.000153         28\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# üß≠ Appel de la fonction sur ton jeu de mod√®les OLS\n",
    "# ----------------------------------------------------------\n",
    "perm_df = permutation_importance_pseudo_oos(\n",
    "    models=models,\n",
    "    df_train_global=df_train_global,\n",
    "    cols_tx=cols_tx,\n",
    "    h=h,\n",
    "    n_repeats=20  # augmente √† 50 pour des r√©sultats plus stables\n",
    ")\n",
    "\n",
    "print(\"\\n=== üîç Importance par permutation (pseudo‚ÄìOOS) ===\")\n",
    "print(perm_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a06ae",
   "metadata": {},
   "source": [
    "Ton mod√®le OLS pr√©dit principalement le ch√¥mage via le cycle √©conomique :\n",
    "- USREC (r√©cession) est la variable cl√© ‚Äî sa permutation d√©grade la performance de ~9 %.\n",
    "- TB3MS (taux court) joue un r√¥le secondaire.\n",
    "- Les autres variables ont un effet n√©gligeable.\n",
    "\n",
    "Conclusion : le pouvoir pr√©dictif du mod√®le vient surtout des variables cycliques (r√©cession, taux), les autres apportent peu d‚Äôinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cf89f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== üí° Importance SHAP (shares) ===\n",
      "       variable  shap_mean_abs  shap_share\n",
      "          TB3MS       0.148710    0.485751\n",
      "          USREC       0.124740    0.407453\n",
      "        S&P 500       0.017688    0.057777\n",
      "      OILPRICEx       0.012534    0.040941\n",
      "DPCERA3M086SBEA       0.001011    0.003303\n",
      "         INDPRO       0.000871    0.002845\n",
      "       CPIAUCSL       0.000309    0.001010\n",
      "           M2SL       0.000204    0.000667\n",
      "            RPI       0.000043    0.000139\n",
      "       BUSLOANS       0.000035    0.000114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Portofolio Data science\\Time Series\\Travaux pratiques Bases\\.venv\\Lib\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üí° IMPORTANCE SHAPLEY (pour mod√®le OLS)\n",
    "# ==========================================================\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ On utilise le dernier mod√®le entra√Æn√©\n",
    "model_final = models[-1]\n",
    "\n",
    "# 2Ô∏è‚É£ On reconstitue ses donn√©es finales (derni√®re fen√™tre du train)\n",
    "df_final = df_train_global.copy()\n",
    "X_full = df_final[cols_tx].iloc[:-h].copy()\n",
    "Y_full = df_final[\"UNRATE\"].shift(-h).iloc[:-h].copy()\n",
    "valid = ~(X_full.isnull().any(axis=1) | Y_full.isnull())\n",
    "X_full = X_full.loc[valid]\n",
    "Y_full = Y_full.loc[valid]\n",
    "\n",
    "# 3Ô∏è‚É£ Calcul des valeurs SHAP\n",
    "# Pour les mod√®les lin√©aires, on peut utiliser shap.LinearExplainer (plus stable)\n",
    "explainer = shap.LinearExplainer(model_final, X_full, feature_perturbation=\"interventional\")\n",
    "shap_values = explainer(X_full)\n",
    "\n",
    "# 4Ô∏è‚É£ Importance moyenne absolue\n",
    "shap_df = pd.DataFrame({\n",
    "    \"variable\": X_full.columns,\n",
    "    \"shap_mean_abs\": np.abs(shap_values.values).mean(axis=0),\n",
    "})\n",
    "shap_df[\"shap_share\"] = shap_df[\"shap_mean_abs\"] / shap_df[\"shap_mean_abs\"].sum()\n",
    "shap_df = shap_df.sort_values(\"shap_mean_abs\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5Ô∏è‚É£ Affichage\n",
    "print(\"\\n=== üí° Importance SHAP (shares) ===\")\n",
    "print(shap_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47ec9c",
   "metadata": {},
   "source": [
    "- TB3MS (0.49)\tüü¢ Repr√©sente ~49 % de l‚Äôinfluence totale du mod√®le. Le taux d‚Äôint√©r√™t √† 3 mois est donc la variable la plus d√©terminante pour les pr√©visions du ch√¥mage : quand les taux montent, le mod√®le anticipe souvent une hausse future du ch√¥mage.\n",
    "\n",
    "- USREC (0.41)\tüîµ Repr√©sente ~41 % de l‚Äôinfluence totale. Le dummy de r√©cession (NBER) p√®se presque autant : le simple fait d‚Äô√™tre en r√©cession ou non explique une large part des variations pr√©vues du ch√¥mage.\n",
    "\n",
    "- S&P 500, OILPRICEx üü† Poids faibles (~6 % et 4 %) : les conditions boursi√®res et le prix du p√©trole ont un impact marginal dans la version lin√©aire du mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7b28b",
   "metadata": {},
   "source": [
    "# üìä M√©triques utilis√©es\n",
    "\n",
    "## 1) Performance globale\n",
    "\n",
    "**Coefficient de d√©termination (R¬≤)**  \n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}\n",
    "$$  \n",
    "‚û°Ô∏è Part de la variance expliqu√©e par le mod√®le (0 = pas mieux que la moyenne, 1 = parfait).\n",
    "\n",
    "**Erreur absolue moyenne (MAE)**  \n",
    "$$\n",
    "MAE = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "$$  \n",
    "‚û°Ô∏è √âcart absolu moyen entre valeurs r√©elles et pr√©dites, robuste aux outliers.\n",
    "\n",
    "**Erreur quadratique moyenne (RMSE)**  \n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$  \n",
    "‚û°Ô∏è Similaire au MAE mais p√©nalise davantage les grosses erreurs.\n",
    "\n",
    "**Corr√©lation de Pearson**  \n",
    "$$\n",
    "\\rho(y, \\hat{y}) = \\frac{\\text{Cov}(y, \\hat{y})}{\\sigma_y \\cdot \\sigma_{\\hat{y}}}\n",
    "$$  \n",
    "‚û°Ô∏è Mesure le degr√© de lien lin√©aire entre les pr√©dictions et les observations.\n",
    "\n",
    "**Abs Mean Deviance (AMD)**  \n",
    "$$\n",
    "AMD = \\frac{1}{n}\\sum_{i=1}^n |\\hat{y}_i - \\bar{\\hat{y}}|\n",
    "$$  \n",
    "‚û°Ô∏è √âcart moyen des pr√©dictions par rapport √† leur moyenne ; sert de r√©f√©rence pour la permutation pr√©diction-bas√©e.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Importance par permutation\n",
    "La relation entre Y et X d√©pend du temps. Quand on perturbe la s√©rie X (en la m√©langeant), on casse ce lien, et si l‚Äôerreur augmente, cela montre que X est une variable cl√© pour expliquer Y.\n",
    "\n",
    "**Ratio MAE**  \n",
    "$$\n",
    "PI^{MAE}_j = \\frac{MAE^{(perm)}_j}{MAE^{(base)}}\n",
    "$$  \n",
    "‚û°Ô∏è Si > 1, la variable est utile pour r√©duire l‚Äôerreur absolue.\n",
    "\n",
    "**Ratio RMSE**  \n",
    "$$\n",
    "PI^{RMSE}_j = \\frac{RMSE^{(perm)}_j}{RMSE^{(base)}}\n",
    "$$  \n",
    "‚û°Ô∏è Si > 1, la variable aide √† limiter les grosses erreurs.\n",
    "\n",
    "**D√©viance de pr√©diction**  \n",
    "$$\n",
    "PI^{dev}_j = \\frac{1}{n}\\sum_{i=1}^n \\big|\\hat{y}_i - \\hat{y}^{(perm)}_{i,j}\\big|\n",
    "$$  \n",
    "‚û°Ô∏è Mesure combien les pr√©dictions changent quand on brouille une variable.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Importance Shapley\n",
    "\n",
    "**D√©composition des pr√©dictions**  \n",
    "$$\n",
    "\\hat{y}_i = \\phi_0 + \\sum_{j=1}^p \\phi_{ij}\n",
    "$$  \n",
    "‚û°Ô∏è Chaque pr√©diction est expliqu√©e par une contribution \\(\\phi_{ij}\\) par variable.\n",
    "\n",
    "**Importance absolue moyenne**  \n",
    "$$\n",
    "\\text{Mean}(|\\phi_j|) = \\frac{1}{n}\\sum_{i=1}^n |\\phi_{ij}|\n",
    "$$  \n",
    "‚û°Ô∏è Contribution moyenne (absolue) d‚Äôune variable sur toutes les pr√©dictions.\n",
    "\n",
    "**Shapley share**  \n",
    "$$\n",
    "\\Gamma_j = \\frac{\\text{Mean}(|\\phi_j|)}{\\sum_{k=1}^p \\text{Mean}(|\\phi_k|)}\n",
    "$$  \n",
    "‚û°Ô∏è Part relative de la variable dans l‚Äôexplication totale (somme des parts = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6535a",
   "metadata": {},
   "source": [
    "## Interpr√©tation des r√©sultats \n",
    "\n",
    "### Performance globale \n",
    "- R¬≤ = 0.2266 ‚Üí mod√®le OLS explique ~23 % de la variance du ch√¥mage US.\n",
    "- MAE = 0.6774 ‚Üí en moyenne, l‚Äôerreur absolue est de 0.68 points (dans l‚Äôunit√© de la variable cible).\n",
    "- RMSE = 0.8750 ‚Üí un peu plus √©lev√© que le MAE, ce qui indique la pr√©sence de grosses erreurs ponctuelles.\n",
    "- Corr√©lation = 0.4760 (p ‚âà 10‚Åª¬≥‚Åµ) ‚Üí lien positif et significatif entre pr√©dictions et observations, mais seulement mod√©r√©. Ce qui peut expliquer la pr√©sence d'une relation \n",
    "- Abs Mean Deviance = 0.3370 ‚Üí sert ici de r√©f√©rence pour l‚Äôimportance pr√©diction-bas√©e : les pr√©dictions s‚Äô√©cartent en moyenne de 0.34 de leur propre moyenne.\n",
    "\n",
    "Lecture : le mod√®le OLS capte une partie utile du signal, mais laisse beaucoup de variance inexpliqu√©e. La corr√©lation faible illustre √©ventuellement la pr√©sence des relations non-lin√©aire, et non capt√©es par OLS.\n",
    "\n",
    "### üîπ 2. Importance par permutation\n",
    "- INDPRO (Industrial Production) : la plus influente. Sa permutation augmente MAE de +19 % et RMSE de +20 %, avec une forte d√©viance de pr√©diction (0.41).\n",
    "- TB3MS (Taux d‚Äôint√©r√™t √† 3 mois) : impact non n√©gligeable, ratios ~1.02 et d√©viance ~0.10.\n",
    "- BUSLOANS (Pr√™ts commerciaux) : r√¥le similaire (MAE ratio 1.017, d√©viance ~0.09).\n",
    "- S&P 500 : contribution mod√©r√©e, ratios l√©g√®rement > 1.\n",
    "- RPI, M2SL : influence plus faible mais perceptible.\n",
    "- CPIAUCSL, OILPRICEx, DPCERA3M086SBEA : quasi neutres (ratios ‚âà 1, d√©viance tr√®s faible).\n",
    "\n",
    "Lecture : INDPRO domine largement la performance, les autres apportent des compl√©ments mais plus modestes.\n",
    "\n",
    "### üîπ 3. Importance Shapley (shares)\n",
    "- INDPRO : ~52 % de l‚Äôexplication totale des pr√©dictions ‚Üí coh√©rence parfaite avec la permutation.\n",
    "- TB3MS (12 %) + BUSLOANS (12 %) : deux autres piliers importants.\n",
    "- S&P 500 (9,7 %) : contribue de fa√ßon notable.\n",
    "- M2SL (5 %), RPI (3 %), CPIAUCSL (3,5 %) : apports plus secondaires.\n",
    "- OILPRICEx et DPCERA3M086SBEA (<2 %) : quasi n√©gligeables dans ce mod√®le.\n",
    "\n",
    "Lecture : INDPRO est la variable macro√©conomique centrale, suivie par des indicateurs financiers (taux courts, pr√™ts bancaires, march√© actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3b489",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "662bb79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le 'OLS_h12_expanding_window' sauvegard√© sous 'OLS_h12_expanding_window.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# üîñ Nom du mod√®le\n",
    "model_name = \"OLS_h12_expanding_window\"\n",
    "\n",
    "# üîπ Rassembler tout dans un dictionnaire structur√©\n",
    "exp_results = {\n",
    "    \"model_name\": model_name,\n",
    "    \"model_type\": \"LinearRegression (OLS)\",\n",
    "    \"description\": \"Mod√®le OLS avec fen√™tre expanding, horizon h=12 mois.\",\n",
    "    \"models\": models,\n",
    "    \"coefs\": coefs,\n",
    "    \"intercepts\": intercepts,\n",
    "    \"train_periods\": train_periods,\n",
    "    \"forecast_records\": forecast_records,\n",
    "    \"params\": {\n",
    "        \"h\": h,\n",
    "        \"step_size\": step_size,\n",
    "        \"winsor_level\": winsor_level,\n",
    "        \"norm_var\": True,\n",
    "        \"features\": cols_tx\n",
    "    }\n",
    "}\n",
    "\n",
    "# üî∏ Nom du fichier de sortie (automatique)\n",
    "file_name = f\"{model_name}.pkl\"\n",
    "\n",
    "# üíæ Sauvegarde\n",
    "with open(file_name, \"wb\") as f:\n",
    "    pickle.dump(exp_results, f)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le '{model_name}' sauvegard√© sous '{file_name}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Travaux pratiques Bases)",
   "language": "python",
   "name": "venv-travaux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
